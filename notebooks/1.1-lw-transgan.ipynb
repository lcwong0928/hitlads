{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ae112aa-175e-4af5-9a19-74aebac7aac8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "import logging\n",
    "import os\n",
    "import pathlib\n",
    "import re\n",
    "import string\n",
    "import sys\n",
    "import time\n",
    "import math\n",
    "import tempfile\n",
    "from functools import partial\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from orion.data import load_signal\n",
    "from orion import Orion\n",
    "from orion.data import load_anomalies\n",
    "\n",
    "from mlprimitives.custom.timeseries_preprocessing import time_segments_aggregate\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from mlprimitives.custom.timeseries_preprocessing import rolling_window_sequences\n",
    "from orion.primitives.timeseries_preprocessing import slice_array_by_dims\n",
    "from mlprimitives import load_primitive\n",
    "import numpy as np\n",
    "from orion.primitives.tadgan import TadGAN\n",
    "\n",
    "from tensorflow.keras import backend as K\n",
    "from keras.layers.merge import _Merge\n",
    "\n",
    "logging.getLogger('tensorflow').setLevel(logging.ERROR)  # suppress warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05293c8e-2839-4598-821d-474857b6cabf",
   "metadata": {},
   "source": [
    "# Positional encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b93e416-9b47-4fa6-a5d1-a488a858b7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_angles(pos, i, d_model):\n",
    "    angle_rates = 1 / np.power(10000, (2 * (i//2)) / np.float32(d_model))\n",
    "    return pos * angle_rates\n",
    "\n",
    "def positional_encoding(position, d_model):\n",
    "    angle_rads = get_angles(np.arange(position)[:, np.newaxis],\n",
    "                          np.arange(d_model)[np.newaxis, :],\n",
    "                          d_model)\n",
    "\n",
    "    # apply sin to even indices in the array; 2i\n",
    "    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
    "\n",
    "    # apply cos to odd indices in the array; 2i+1\n",
    "    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
    "\n",
    "    pos_encoding = angle_rads[np.newaxis, ...]\n",
    "\n",
    "    return tf.cast(pos_encoding, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d3b2020-d0f2-4ce0-8133-9d524f936295",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 100, 25)\n"
     ]
    }
   ],
   "source": [
    "# Test Example\n",
    "n, d = 100, 25\n",
    "pos_encoding = positional_encoding(n, d)\n",
    "print(pos_encoding.shape)\n",
    "pos_encoding = pos_encoding[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e0b0eb-46f3-4159-9811-ee0333650a97",
   "metadata": {},
   "source": [
    "# Masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1908e393-966f-4226-83fe-4088a630dd8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_padding_mask(seq):\n",
    "    seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
    "\n",
    "    # add extra dimensions to add the padding\n",
    "    # to the attention logits.\n",
    "    return seq[:, tf.newaxis, tf.newaxis, :]  # (batch_size, 1, 1, seq_len)\n",
    "\n",
    "def create_look_ahead_mask(size):\n",
    "    mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
    "    return mask  # (seq_len, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12db03fc-440a-410f-be3e-36c5fd2b44c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'strided_slice_1:0' shape=(3, 1, 1, 5) dtype=float32>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 0 are pads\n",
    "x = tf.constant([[7, 6, 0, 0, 1], [1, 2, 3, 0, 0], [0, 0, 0, 4, 5]])\n",
    "create_padding_mask(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87a9daaa-c2e1-462d-8989-fe838d53c5f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'sub:0' shape=(3, 3) dtype=float32>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look-ahead mask\n",
    "x = tf.random.uniform((1, 3))\n",
    "temp = create_look_ahead_mask(x.shape[1])\n",
    "temp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a085f38-a11e-41d0-a0d2-708347dc411f",
   "metadata": {},
   "source": [
    "# Multihead Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb305436-3f9b-42b5-8e46-e9153544bd06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(q, k, v, mask):\n",
    "  \"\"\"Calculate the attention weights.\n",
    "  q, k, v must have matching leading dimensions.\n",
    "  k, v must have matching penultimate dimension, i.e.: seq_len_k = seq_len_v.\n",
    "  The mask has different shapes depending on its type(padding or look ahead)\n",
    "  but it must be broadcastable for addition.\n",
    "\n",
    "  Args:\n",
    "    q: query shape == (..., seq_len_q, depth)\n",
    "    k: key shape == (..., seq_len_k, depth)\n",
    "    v: value shape == (..., seq_len_v, depth_v)\n",
    "    mask: Float tensor with shape broadcastable\n",
    "          to (..., seq_len_q, seq_len_k). Defaults to None.\n",
    "\n",
    "  Returns:\n",
    "    output, attention_weights\n",
    "  \"\"\"\n",
    "\n",
    "  matmul_qk = tf.matmul(q, k, transpose_b=True)  # (..., seq_len_q, seq_len_k)\n",
    "\n",
    "  # scale matmul_qk\n",
    "  dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
    "  scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
    "\n",
    "  # add the mask to the scaled tensor.\n",
    "  if mask is not None:\n",
    "    scaled_attention_logits += (mask * -1e9)\n",
    "\n",
    "  # softmax is normalized on the last axis (seq_len_k) so that the scores\n",
    "  # add up to 1.\n",
    "  attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)  # (..., seq_len_q, seq_len_k)\n",
    "\n",
    "  output = tf.matmul(attention_weights, v)  # (..., seq_len_q, depth_v)\n",
    "\n",
    "  return output, attention_weights\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "  def __init__(self, d_model, num_heads):\n",
    "    super(MultiHeadAttention, self).__init__()\n",
    "    self.num_heads = num_heads\n",
    "    self.d_model = d_model\n",
    "\n",
    "    assert d_model % self.num_heads == 0\n",
    "\n",
    "    self.depth = d_model // self.num_heads\n",
    "\n",
    "    self.wq = tf.keras.layers.Dense(d_model)\n",
    "    self.wk = tf.keras.layers.Dense(d_model)\n",
    "    self.wv = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "    self.dense = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "  def split_heads(self, x, batch_size):\n",
    "    \"\"\"Split the last dimension into (num_heads, depth).\n",
    "    Transpose the result such that the shape is (batch_size, num_heads, seq_len, depth)\n",
    "    \"\"\"\n",
    "    x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
    "    return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "\n",
    "  def call(self, v, k, q, mask):\n",
    "    batch_size = tf.shape(q)[0]\n",
    "\n",
    "    q = self.wq(q)  # (batch_size, seq_len, d_model)\n",
    "    k = self.wk(k)  # (batch_size, seq_len, d_model)\n",
    "    v = self.wv(v)  # (batch_size, seq_len, d_model)\n",
    "\n",
    "    q = self.split_heads(q, batch_size)  # (batch_size, num_heads, seq_len_q, depth)\n",
    "    k = self.split_heads(k, batch_size)  # (batch_size, num_heads, seq_len_k, depth)\n",
    "    v = self.split_heads(v, batch_size)  # (batch_size, num_heads, seq_len_v, depth)\n",
    "\n",
    "    # scaled_attention.shape == (batch_size, num_heads, seq_len_q, depth)\n",
    "    # attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)\n",
    "    scaled_attention, attention_weights = scaled_dot_product_attention(\n",
    "        q, k, v, mask)\n",
    "\n",
    "    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])  # (batch_size, seq_len_q, num_heads, depth)\n",
    "\n",
    "    concat_attention = tf.reshape(scaled_attention,\n",
    "                                  (batch_size, -1, self.d_model))  # (batch_size, seq_len_q, d_model)\n",
    "\n",
    "    output = self.dense(concat_attention)  # (batch_size, seq_len_q, d_model)\n",
    "\n",
    "    return output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a4d23b15-69ed-4322-b5d8-35c21ac50349",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([Dimension(1), Dimension(100), Dimension(25)]),\n",
       " TensorShape([Dimension(1), Dimension(5), Dimension(100), Dimension(100)]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_mha = MultiHeadAttention(d_model=25, num_heads=5)\n",
    "y = tf.random.uniform((1, 100, 25))  # (batch_size, encoder_sequence, d_model)\n",
    "out, attn = temp_mha(y, k=y, q=y, mask=None)\n",
    "out.shape, attn.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7904c053-5e6e-46ce-bc23-b4dba7fb400e",
   "metadata": {},
   "source": [
    "# Point wise feed forward network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a0b74c2-1bd3-425e-af7d-6ce9573d867d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def point_wise_feed_forward_network(d_model, dff):\n",
    "    return tf.keras.Sequential([\n",
    "      tf.keras.layers.Dense(dff, activation='relu'),  # (batch_size, seq_len, dff)\n",
    "      tf.keras.layers.Dense(d_model)  # (batch_size, seq_len, d_model)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bc8e4477-b6da-4d01-8d05-188e9aebfc7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(64), Dimension(50), Dimension(512)])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_ffn = point_wise_feed_forward_network(512, 2048)\n",
    "sample_ffn(tf.random.uniform((64, 50, 512))).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e10ecd-397e-43bb-8d8b-fcf162301da0",
   "metadata": {},
   "source": [
    "# Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a9ba7c04-df76-45ea-82d6-87d5c6064cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "  def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
    "    super(EncoderLayer, self).__init__()\n",
    "\n",
    "    self.mha = MultiHeadAttention(d_model, num_heads)\n",
    "    self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
    "\n",
    "    self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "    self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "    self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "    self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "\n",
    "  def call(self, x, training, mask):\n",
    "\n",
    "    attn_output, _ = self.mha(x, x, x, mask)  # (batch_size, input_seq_len, d_model)\n",
    "    attn_output = self.dropout1(attn_output, training=training)\n",
    "    out1 = self.layernorm1(x + attn_output)  # (batch_size, input_seq_len, d_model)\n",
    "\n",
    "    ffn_output = self.ffn(out1)  # (batch_size, input_seq_len, d_model)\n",
    "    ffn_output = self.dropout2(ffn_output, training=training)\n",
    "    out2 = self.layernorm2(out1 + ffn_output)  # (batch_size, input_seq_len, d_model)\n",
    "\n",
    "    return out2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "60cbc86f-0d71-423b-a79c-1e4c18a7512e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(64), Dimension(43), Dimension(512)])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_encoder_layer = EncoderLayer(512, 8, 2048)\n",
    "\n",
    "sample_encoder_layer_output = sample_encoder_layer(\n",
    "    tf.random.uniform((64, 43, 512)), False, None)\n",
    "\n",
    "sample_encoder_layer_output.shape  # (batch_size, input_seq_len, d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8425c956-a251-4698-8bec-6e30dd9cb3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.layers.Layer):\n",
    "  def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size,\n",
    "               maximum_position_encoding, rate=0.1):\n",
    "    super(Encoder, self).__init__()\n",
    "\n",
    "    self.d_model = d_model\n",
    "    self.num_layers = num_layers\n",
    "\n",
    "    # self.embedding = tf.keras.layers.Embedding(input_vocab_size, d_model)\n",
    "    self.pos_encoding = positional_encoding(maximum_position_encoding,\n",
    "                                            self.d_model)\n",
    "\n",
    "    self.enc_layers = [EncoderLayer(d_model, num_heads, dff, rate)\n",
    "                       for _ in range(num_layers)]\n",
    "\n",
    "    self.dropout = tf.keras.layers.Dropout(rate)\n",
    "\n",
    "  def call(self, x, training, mask):\n",
    "\n",
    "    seq_len = tf.shape(x)[1]\n",
    "\n",
    "    # adding embedding and position encoding.\n",
    "    # x = self.embedding(x)  # (batch_size, input_seq_len, d_model)\n",
    "    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "    x += self.pos_encoding[:, :seq_len, :]\n",
    "   \n",
    "\n",
    "    x = self.dropout(x, training=training)\n",
    "\n",
    "    for i in range(self.num_layers):\n",
    "      x = self.enc_layers[i](x, training, mask)\n",
    "\n",
    "    return x  # (batch_size, input_seq_len, d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a4de6f8c-0410-4eb5-ac11-f7971bf73c5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 100, 25)\n"
     ]
    }
   ],
   "source": [
    "sample_encoder = Encoder(num_layers=2, d_model=25, num_heads=5,\n",
    "                         dff=1, input_vocab_size=None,\n",
    "                         maximum_position_encoding=10000)\n",
    "temp_input = tf.random.uniform((1, 100, 25), dtype=tf.float32, minval=0, maxval=200)\n",
    "\n",
    "sample_encoder_output = sample_encoder(temp_input, training=False, mask=None)\n",
    "\n",
    "print(sample_encoder_output.shape)  # (batch_size, input_seq_len, d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "00004a60-9258-4150-be69-7999f906b651",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_encoder.trainable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82983a06-dfde-4907-a376-edb7b2cf88b1",
   "metadata": {},
   "source": [
    "# Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c473c4fb-fb1c-4ca9-b0f8-5f4c94ce8d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(tf.keras.layers.Layer):\n",
    "  def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
    "    super(DecoderLayer, self).__init__()\n",
    "\n",
    "    self.mha1 = MultiHeadAttention(d_model, num_heads)\n",
    "    self.mha2 = MultiHeadAttention(d_model, num_heads)\n",
    "\n",
    "    self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
    "\n",
    "    self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "    self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "    self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "    self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "    self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "    self.dropout3 = tf.keras.layers.Dropout(rate)\n",
    "\n",
    "  def call(self, x, enc_output, training,\n",
    "           look_ahead_mask, padding_mask):\n",
    "    # enc_output.shape == (batch_size, input_seq_len, d_model)\n",
    "\n",
    "    attn1, attn_weights_block1 = self.mha1(x, x, x, look_ahead_mask)  # (batch_size, target_seq_len, d_model)\n",
    "    attn1 = self.dropout1(attn1, training=training)\n",
    "    out1 = self.layernorm1(attn1 + x)\n",
    "\n",
    "    attn2, attn_weights_block2 = self.mha2(\n",
    "        enc_output, enc_output, out1, padding_mask)  # (batch_size, target_seq_len, d_model)\n",
    "    attn2 = self.dropout2(attn2, training=training)\n",
    "    out2 = self.layernorm2(attn2 + out1)  # (batch_size, target_seq_len, d_model)\n",
    "\n",
    "    ffn_output = self.ffn(out2)  # (batch_size, target_seq_len, d_model)\n",
    "    ffn_output = self.dropout3(ffn_output, training=training)\n",
    "    out3 = self.layernorm3(ffn_output + out2)  # (batch_size, target_seq_len, d_model)\n",
    "\n",
    "    return out3, attn_weights_block1, attn_weights_block2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b613520c-ff78-40fb-9e07-2191b29b45e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(64), Dimension(50), Dimension(512)])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_decoder_layer = DecoderLayer(512, 8, 2048)\n",
    "\n",
    "sample_decoder_layer_output, _, _ = sample_decoder_layer(\n",
    "    tf.random.uniform((64, 50, 512)), sample_encoder_layer_output,\n",
    "    False, None, None)\n",
    "\n",
    "sample_decoder_layer_output.shape  # (batch_size, target_seq_len, d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cc85bb54-508f-47a1-a76d-37f9fcfcd1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.layers.Layer):\n",
    "  def __init__(self, num_layers, d_model, num_heads, dff, target_vocab_size,\n",
    "               maximum_position_encoding, rate=0.1):\n",
    "    super(Decoder, self).__init__()\n",
    "\n",
    "    self.d_model = d_model\n",
    "    self.num_layers = num_layers\n",
    "\n",
    "    self.embedding = tf.keras.layers.Embedding(target_vocab_size, d_model)\n",
    "    self.pos_encoding = positional_encoding(maximum_position_encoding, d_model)\n",
    "\n",
    "    self.dec_layers = [DecoderLayer(d_model, num_heads, dff, rate)\n",
    "                       for _ in range(num_layers)]\n",
    "    self.dropout = tf.keras.layers.Dropout(rate)\n",
    "\n",
    "  def call(self, x, enc_output, training,\n",
    "           look_ahead_mask, padding_mask):\n",
    "\n",
    "    seq_len = tf.shape(x)[1]\n",
    "    attention_weights = {}\n",
    "\n",
    "    x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
    "    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "    x += self.pos_encoding[:, :seq_len, :]\n",
    "\n",
    "    x = self.dropout(x, training=training)\n",
    "\n",
    "    for i in range(self.num_layers):\n",
    "      x, block1, block2 = self.dec_layers[i](x, enc_output, training,\n",
    "                                             look_ahead_mask, padding_mask)\n",
    "\n",
    "      attention_weights[f'decoder_layer{i+1}_block1'] = block1\n",
    "      attention_weights[f'decoder_layer{i+1}_block2'] = block2\n",
    "\n",
    "    # x.shape == (batch_size, target_seq_len, d_model)\n",
    "    return x, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b06b7fbe-a7f0-4de4-b64f-7e72e21eaad4",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in converted code:\n\n    /var/folders/_5/f7yzqnxs6694l3c_yk9mjpzr0000gn/T/ipykernel_48479/955386546.py:29 call  *\n        x, block1, block2 = self.dec_layers[i](x, enc_output, training,\n    /Users/lcwong/opt/anaconda3/envs/orion-env/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py:854 __call__\n        outputs = call_fn(cast_inputs, *args, **kwargs)\n    /var/folders/_5/f7yzqnxs6694l3c_yk9mjpzr0000gn/T/ipykernel_48479/1969818830.py:26 call  *\n        attn2, attn_weights_block2 = self.mha2(\n    /Users/lcwong/opt/anaconda3/envs/orion-env/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py:854 __call__\n        outputs = call_fn(cast_inputs, *args, **kwargs)\n    /var/folders/_5/f7yzqnxs6694l3c_yk9mjpzr0000gn/T/ipykernel_48479/3292487066.py:71 call  *\n        k = self.split_heads(k, batch_size)  # (batch_size, num_heads, seq_len_k, depth)\n    /var/folders/_5/f7yzqnxs6694l3c_yk9mjpzr0000gn/T/ipykernel_48479/3292487066.py:60 split_heads  *\n        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n    /Users/lcwong/opt/anaconda3/envs/orion-env/lib/python3.7/site-packages/tensorflow_core/python/ops/array_ops.py:131 reshape\n        result = gen_array_ops.reshape(tensor, shape, name)\n    /Users/lcwong/opt/anaconda3/envs/orion-env/lib/python3.7/site-packages/tensorflow_core/python/ops/gen_array_ops.py:8115 reshape\n        \"Reshape\", tensor=tensor, shape=shape, name=name)\n    /Users/lcwong/opt/anaconda3/envs/orion-env/lib/python3.7/site-packages/tensorflow_core/python/framework/op_def_library.py:794 _apply_op_helper\n        op_def=op_def)\n    /Users/lcwong/opt/anaconda3/envs/orion-env/lib/python3.7/site-packages/tensorflow_core/python/util/deprecation.py:507 new_func\n        return func(*args, **kwargs)\n    /Users/lcwong/opt/anaconda3/envs/orion-env/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py:3357 create_op\n        attrs, op_def, compute_device)\n    /Users/lcwong/opt/anaconda3/envs/orion-env/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py:3426 _create_op_internal\n        op_def=op_def)\n    /Users/lcwong/opt/anaconda3/envs/orion-env/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py:1770 __init__\n        control_input_ops)\n    /Users/lcwong/opt/anaconda3/envs/orion-env/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py:1610 _create_c_op\n        raise ValueError(str(e))\n\n    ValueError: Dimension size must be evenly divisible by 32768 but is 51200 for 'decoder/decoder_layer_1/multi_head_attention_7/Reshape_1' (op: 'Reshape') with input shapes: [1,100,512], [4] and with input tensors computed as partial shapes: input[1] = [64,?,8,64].\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/_5/f7yzqnxs6694l3c_yk9mjpzr0000gn/T/ipykernel_48479/3239313571.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m                               \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m                               \u001b[0mlook_ahead_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m                               padding_mask=None)\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'decoder_layer2_block2'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/orion-env/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    852\u001b[0m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_layer_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmark_as_return\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 854\u001b[0;31m                   \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    855\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    856\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOperatorNotAllowedInGraphError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/orion-env/lib/python3.7/site-packages/tensorflow_core/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    235\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m           \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m           \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in converted code:\n\n    /var/folders/_5/f7yzqnxs6694l3c_yk9mjpzr0000gn/T/ipykernel_48479/955386546.py:29 call  *\n        x, block1, block2 = self.dec_layers[i](x, enc_output, training,\n    /Users/lcwong/opt/anaconda3/envs/orion-env/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py:854 __call__\n        outputs = call_fn(cast_inputs, *args, **kwargs)\n    /var/folders/_5/f7yzqnxs6694l3c_yk9mjpzr0000gn/T/ipykernel_48479/1969818830.py:26 call  *\n        attn2, attn_weights_block2 = self.mha2(\n    /Users/lcwong/opt/anaconda3/envs/orion-env/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py:854 __call__\n        outputs = call_fn(cast_inputs, *args, **kwargs)\n    /var/folders/_5/f7yzqnxs6694l3c_yk9mjpzr0000gn/T/ipykernel_48479/3292487066.py:71 call  *\n        k = self.split_heads(k, batch_size)  # (batch_size, num_heads, seq_len_k, depth)\n    /var/folders/_5/f7yzqnxs6694l3c_yk9mjpzr0000gn/T/ipykernel_48479/3292487066.py:60 split_heads  *\n        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n    /Users/lcwong/opt/anaconda3/envs/orion-env/lib/python3.7/site-packages/tensorflow_core/python/ops/array_ops.py:131 reshape\n        result = gen_array_ops.reshape(tensor, shape, name)\n    /Users/lcwong/opt/anaconda3/envs/orion-env/lib/python3.7/site-packages/tensorflow_core/python/ops/gen_array_ops.py:8115 reshape\n        \"Reshape\", tensor=tensor, shape=shape, name=name)\n    /Users/lcwong/opt/anaconda3/envs/orion-env/lib/python3.7/site-packages/tensorflow_core/python/framework/op_def_library.py:794 _apply_op_helper\n        op_def=op_def)\n    /Users/lcwong/opt/anaconda3/envs/orion-env/lib/python3.7/site-packages/tensorflow_core/python/util/deprecation.py:507 new_func\n        return func(*args, **kwargs)\n    /Users/lcwong/opt/anaconda3/envs/orion-env/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py:3357 create_op\n        attrs, op_def, compute_device)\n    /Users/lcwong/opt/anaconda3/envs/orion-env/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py:3426 _create_op_internal\n        op_def=op_def)\n    /Users/lcwong/opt/anaconda3/envs/orion-env/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py:1770 __init__\n        control_input_ops)\n    /Users/lcwong/opt/anaconda3/envs/orion-env/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py:1610 _create_c_op\n        raise ValueError(str(e))\n\n    ValueError: Dimension size must be evenly divisible by 32768 but is 51200 for 'decoder/decoder_layer_1/multi_head_attention_7/Reshape_1' (op: 'Reshape') with input shapes: [1,100,512], [4] and with input tensors computed as partial shapes: input[1] = [64,?,8,64].\n"
     ]
    }
   ],
   "source": [
    "sample_decoder = Decoder(num_layers=2, d_model=512, num_heads=8,\n",
    "                         dff=2048, target_vocab_size=8000,\n",
    "                         maximum_position_encoding=5000)\n",
    "temp_input = tf.random.uniform((64, 26), dtype=tf.float32, minval=0, maxval=200)\n",
    "\n",
    "output, attn = sample_decoder(temp_input,\n",
    "                              enc_output=sample_encoder_output,\n",
    "                              training=False,\n",
    "                              look_ahead_mask=None,\n",
    "                              padding_mask=None)\n",
    "\n",
    "output.shape, attn['decoder_layer2_block2'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2180e4ff-1377-4360-bcd0-71e43a27f516",
   "metadata": {},
   "source": [
    "# Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f64faf67-e037-45bf-8a5e-cdfb28ccb5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(tf.keras.Model):\n",
    "  def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size,\n",
    "               target_vocab_size, pe_input, pe_target, rate=0.1):\n",
    "    super().__init__()\n",
    "    self.encoder = Encoder(num_layers, d_model, num_heads, dff,\n",
    "                             input_vocab_size, pe_input, rate)\n",
    "\n",
    "    self.decoder = Decoder(num_layers, d_model, num_heads, dff,\n",
    "                           target_vocab_size, pe_target, rate)\n",
    "\n",
    "    self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n",
    "\n",
    "  def call(self, inputs, training):\n",
    "    # Keras models prefer if you pass all your inputs in the first argument\n",
    "    inp, tar = inputs\n",
    "\n",
    "    enc_padding_mask, look_ahead_mask, dec_padding_mask = self.create_masks(inp, tar)\n",
    "\n",
    "    enc_output = self.encoder(inp, training, enc_padding_mask)  # (batch_size, inp_seq_len, d_model)\n",
    "\n",
    "    # dec_output.shape == (batch_size, tar_seq_len, d_model)\n",
    "    dec_output, attention_weights = self.decoder(\n",
    "        tar, enc_output, training, look_ahead_mask, dec_padding_mask)\n",
    "\n",
    "    final_output = self.final_layer(dec_output)  # (batch_size, tar_seq_len, target_vocab_size)\n",
    "\n",
    "    return final_output, attention_weights\n",
    "\n",
    "  def create_masks(self, inp, tar):\n",
    "    # Encoder padding mask\n",
    "    enc_padding_mask = create_padding_mask(inp)\n",
    "\n",
    "    # Used in the 2nd attention block in the decoder.\n",
    "    # This padding mask is used to mask the encoder outputs.\n",
    "    dec_padding_mask = create_padding_mask(inp)\n",
    "\n",
    "    # Used in the 1st attention block in the decoder.\n",
    "    # It is used to pad and mask future tokens in the input received by\n",
    "    # the decoder.\n",
    "    look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])\n",
    "    dec_target_padding_mask = create_padding_mask(tar)\n",
    "    look_ahead_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n",
    "\n",
    "    return enc_padding_mask, look_ahead_mask, dec_padding_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "42fc01d0-9ddd-4405-89e1-6a4a6952fa48",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in converted code:\n\n    /var/folders/_5/f7yzqnxs6694l3c_yk9mjpzr0000gn/T/ipykernel_48479/459540881.py:19 call  *\n        enc_output = self.encoder(inp, training, enc_padding_mask)  # (batch_size, inp_seq_len, d_model)\n    /Users/lcwong/opt/anaconda3/envs/orion-env/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py:854 __call__\n        outputs = call_fn(cast_inputs, *args, **kwargs)\n    /var/folders/_5/f7yzqnxs6694l3c_yk9mjpzr0000gn/T/ipykernel_48479/1886624111.py:25 call  *\n        x += self.pos_encoding[:, :seq_len, :]\n    /Users/lcwong/opt/anaconda3/envs/orion-env/lib/python3.7/site-packages/tensorflow_core/python/ops/math_ops.py:899 binary_op_wrapper\n        return func(x, y, name=name)\n    /Users/lcwong/opt/anaconda3/envs/orion-env/lib/python3.7/site-packages/tensorflow_core/python/ops/math_ops.py:1197 _add_dispatch\n        return gen_math_ops.add_v2(x, y, name=name)\n    /Users/lcwong/opt/anaconda3/envs/orion-env/lib/python3.7/site-packages/tensorflow_core/python/ops/gen_math_ops.py:549 add_v2\n        \"AddV2\", x=x, y=y, name=name)\n    /Users/lcwong/opt/anaconda3/envs/orion-env/lib/python3.7/site-packages/tensorflow_core/python/framework/op_def_library.py:794 _apply_op_helper\n        op_def=op_def)\n    /Users/lcwong/opt/anaconda3/envs/orion-env/lib/python3.7/site-packages/tensorflow_core/python/util/deprecation.py:507 new_func\n        return func(*args, **kwargs)\n    /Users/lcwong/opt/anaconda3/envs/orion-env/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py:3357 create_op\n        attrs, op_def, compute_device)\n    /Users/lcwong/opt/anaconda3/envs/orion-env/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py:3426 _create_op_internal\n        op_def=op_def)\n    /Users/lcwong/opt/anaconda3/envs/orion-env/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py:1770 __init__\n        control_input_ops)\n    /Users/lcwong/opt/anaconda3/envs/orion-env/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py:1610 _create_c_op\n        raise ValueError(str(e))\n\n    ValueError: Dimensions must be equal, but are 64 and 38 for 'transformer/encoder_1/add' (op: 'AddV2') with input shapes: [64,38], [1,38,512].\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/_5/f7yzqnxs6694l3c_yk9mjpzr0000gn/T/ipykernel_48479/614437494.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mtemp_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m36\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mfn_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_transformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtemp_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemp_target\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mfn_out\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m  \u001b[0;31m# (batch_size, tar_seq_len, target_vocab_size)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/orion-env/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    852\u001b[0m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_layer_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmark_as_return\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 854\u001b[0;31m                   \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    855\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    856\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOperatorNotAllowedInGraphError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/orion-env/lib/python3.7/site-packages/tensorflow_core/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    235\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m           \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m           \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in converted code:\n\n    /var/folders/_5/f7yzqnxs6694l3c_yk9mjpzr0000gn/T/ipykernel_48479/459540881.py:19 call  *\n        enc_output = self.encoder(inp, training, enc_padding_mask)  # (batch_size, inp_seq_len, d_model)\n    /Users/lcwong/opt/anaconda3/envs/orion-env/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py:854 __call__\n        outputs = call_fn(cast_inputs, *args, **kwargs)\n    /var/folders/_5/f7yzqnxs6694l3c_yk9mjpzr0000gn/T/ipykernel_48479/1886624111.py:25 call  *\n        x += self.pos_encoding[:, :seq_len, :]\n    /Users/lcwong/opt/anaconda3/envs/orion-env/lib/python3.7/site-packages/tensorflow_core/python/ops/math_ops.py:899 binary_op_wrapper\n        return func(x, y, name=name)\n    /Users/lcwong/opt/anaconda3/envs/orion-env/lib/python3.7/site-packages/tensorflow_core/python/ops/math_ops.py:1197 _add_dispatch\n        return gen_math_ops.add_v2(x, y, name=name)\n    /Users/lcwong/opt/anaconda3/envs/orion-env/lib/python3.7/site-packages/tensorflow_core/python/ops/gen_math_ops.py:549 add_v2\n        \"AddV2\", x=x, y=y, name=name)\n    /Users/lcwong/opt/anaconda3/envs/orion-env/lib/python3.7/site-packages/tensorflow_core/python/framework/op_def_library.py:794 _apply_op_helper\n        op_def=op_def)\n    /Users/lcwong/opt/anaconda3/envs/orion-env/lib/python3.7/site-packages/tensorflow_core/python/util/deprecation.py:507 new_func\n        return func(*args, **kwargs)\n    /Users/lcwong/opt/anaconda3/envs/orion-env/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py:3357 create_op\n        attrs, op_def, compute_device)\n    /Users/lcwong/opt/anaconda3/envs/orion-env/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py:3426 _create_op_internal\n        op_def=op_def)\n    /Users/lcwong/opt/anaconda3/envs/orion-env/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py:1770 __init__\n        control_input_ops)\n    /Users/lcwong/opt/anaconda3/envs/orion-env/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py:1610 _create_c_op\n        raise ValueError(str(e))\n\n    ValueError: Dimensions must be equal, but are 64 and 38 for 'transformer/encoder_1/add' (op: 'AddV2') with input shapes: [64,38], [1,38,512].\n"
     ]
    }
   ],
   "source": [
    "sample_transformer = Transformer(\n",
    "    num_layers=2, d_model=512, num_heads=8, dff=2048,\n",
    "    input_vocab_size=8500, target_vocab_size=8000,\n",
    "    pe_input=10000, pe_target=6000)\n",
    "\n",
    "temp_input = tf.random.uniform((64, 38), dtype=tf.float32, minval=0, maxval=200)\n",
    "temp_target = tf.random.uniform((64, 36), dtype=tf.float32, minval=0, maxval=200)\n",
    "\n",
    "fn_out, _ = sample_transformer([temp_input, temp_target], training=False)\n",
    "\n",
    "fn_out.shape  # (batch_size, tar_seq_len, target_vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e06e4164-c620-4e3b-96e4-3589c863f28e",
   "metadata": {},
   "source": [
    "# TadGan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "716a611d-50b9-4def-ad59-784355637c08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2718, 100, 25), TensorShape([Dimension(1), Dimension(100), Dimension(25)]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.load('processed/data/X.npy')\n",
    "target = np.load('processed/data/y.npy')\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b782d889-0ad4-4a37-9a83-349feac64788",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape=(100, 25)\n",
    "target_shape=(100, 1)\n",
    "latent_dim=20\n",
    "learning_rate=0.0005\n",
    "epochs=70\n",
    "batch_size=64\n",
    "iterations_critic=5\n",
    "latent_shape = (latent_dim, 1)\n",
    "\n",
    "shape = np.asarray(X)[0].shape\n",
    "length = shape[0]\n",
    "target_shape = np.asarray(target)[0].shape\n",
    "\n",
    "\n",
    "generator_reshape_dim =  length // 2\n",
    "generator_reshape_shape = (length // 2, 1)\n",
    "encoder_reshape_shape = latent_shape\n",
    "\n",
    "encoder_input_shape = shape\n",
    "generator_input_shape = latent_shape\n",
    "critic_x_input_shape = target_shape\n",
    "critic_z_input_shape = latent_shape\n",
    "\n",
    "\n",
    "\n",
    "lstm_units = 100\n",
    "dense_units = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3b29a316-3e9d-4954-a48d-9024d38435c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 100, 25)]         0         \n",
      "_________________________________________________________________\n",
      "sequential_17 (Sequential)   (None, 20, 1)             55572     \n",
      "=================================================================\n",
      "Total params: 55,572\n",
      "Trainable params: 55,572\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def build_encoder(input_shape, lstm_units, dense_units, encoder_reshape_shape):\n",
    "    x = tf.keras.Input(shape=input_shape)\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(Encoder(num_layers=2, d_model=25, num_heads=5,\n",
    "                      dff=1, input_vocab_size=None,\n",
    "                      maximum_position_encoding=10000))\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    model.add(tf.keras.layers.Dense(units=dense_units))\n",
    "    model.add(tf.keras.layers.Reshape(target_shape=encoder_reshape_shape))\n",
    "    return tf.keras.Model(x, model(x))\n",
    "              \n",
    "encoder = build_encoder(\n",
    "    input_shape=encoder_input_shape,\n",
    "    lstm_units=lstm_units,\n",
    "    dense_units=dense_units,\n",
    "    encoder_reshape_shape=encoder_reshape_shape,\n",
    ")\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9ecd1277-7587-4360-a016-94287c60c33b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 20, 1)]           0         \n",
      "_________________________________________________________________\n",
      "sequential_20 (Sequential)   (None, 100, 1)            133787    \n",
      "=================================================================\n",
      "Total params: 133,787\n",
      "Trainable params: 133,787\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def build_generator(input_shape, generator_reshape_dim, generator_reshape_shape):\n",
    "    x = tf.keras.Input(shape=input_shape)\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    model.add(tf.keras.layers.Dense(units=generator_reshape_dim))\n",
    "    model.add(tf.keras.layers.Reshape(target_shape=generator_reshape_shape))\n",
    "    model.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(units=64, return_sequences=True, dropout=0.2, recurrent_dropout=0.2), merge_mode='concat'))\n",
    "    model.add(tf.keras.layers.UpSampling1D(size=2))\n",
    "    model.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(units=64, return_sequences=True, dropout=0.2, recurrent_dropout=0.2), merge_mode='concat'))\n",
    "    model.add(tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(units=1)))\n",
    "    model.add(tf.keras.layers.Activation(activation='tanh'))\n",
    "    return tf.keras.Model(x, model(x))\n",
    "              \n",
    "generator = build_generator(\n",
    "    input_shape=generator_input_shape,\n",
    "    generator_reshape_dim=generator_reshape_dim,\n",
    "    generator_reshape_shape=generator_reshape_shape,\n",
    ")\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "928b7ad3-2038-4602-a229-2a58ba91fcd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         [(None, 100, 1)]          0         \n",
      "_________________________________________________________________\n",
      "sequential_21 (Sequential)   (None, 1)                 67393     \n",
      "=================================================================\n",
      "Total params: 67,393\n",
      "Trainable params: 67,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def build_critic_x(input_shape):\n",
    "    x = tf.keras.Input(shape=input_shape)\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.Conv1D(filters=64, kernel_size=5))\n",
    "    model.add(tf.keras.layers.LeakyReLU(alpha=0.2))\n",
    "    model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "    model.add(tf.keras.layers.Conv1D(filters=64, kernel_size=5))\n",
    "    model.add(tf.keras.layers.LeakyReLU(alpha=0.2))\n",
    "    model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "    model.add(tf.keras.layers.Conv1D(filters=64, kernel_size=5))\n",
    "    model.add(tf.keras.layers.LeakyReLU(alpha=0.2))\n",
    "    model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "    model.add(tf.keras.layers.Conv1D(filters=64, kernel_size=5))\n",
    "    model.add(tf.keras.layers.LeakyReLU(alpha=0.2))\n",
    "    model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    model.add(tf.keras.layers.Dense(units=1))\n",
    "    return tf.keras.Model(x, model(x))\n",
    "              \n",
    "critic_x = build_critic_x(\n",
    "    input_shape=critic_x_input_shape\n",
    ")\n",
    "critic_x.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "792f35a5-177c-4a40-94a3-9f72dde48214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         [(None, 20, 1)]           0         \n",
      "_________________________________________________________________\n",
      "sequential_22 (Sequential)   (None, 1)                 861       \n",
      "=================================================================\n",
      "Total params: 861\n",
      "Trainable params: 861\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def build_critic_z(input_shape, dense_units=20):\n",
    "    x = tf.keras.Input(shape=input_shape)\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    model.add(tf.keras.layers.Dense(units=dense_units))\n",
    "    model.add(tf.keras.layers.LeakyReLU(alpha=0.2))\n",
    "    model.add(tf.keras.layers.Dropout(rate=0.2))\n",
    "    model.add(tf.keras.layers.Dense(units=dense_units))\n",
    "    model.add(tf.keras.layers.LeakyReLU(alpha=0.2))\n",
    "    model.add(tf.keras.layers.Dropout(rate=0.2))\n",
    "    model.add(tf.keras.layers.Dense(units=1))\n",
    "    return tf.keras.Model(x, model(x))\n",
    "              \n",
    "critic_z = build_critic_z(\n",
    "    input_shape=critic_z_input_shape,\n",
    ")\n",
    "critic_z.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e7972777-6ebf-49ef-b846-bd434440a38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomWeightedAverage(_Merge):\n",
    "    def _merge_function(self, inputs):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            inputs[0] x     original input\n",
    "            inputs[1] x_    predicted input\n",
    "        \"\"\"\n",
    "        alpha = K.random_uniform((64, 1, 1))\n",
    "        return (alpha * inputs[0]) + ((1 - alpha) * inputs[1])\n",
    "\n",
    "def _wasserstein_loss(y_true, y_pred):\n",
    "    return K.mean(y_true * y_pred)\n",
    "\n",
    "def _gradient_penalty_loss(y_true, y_pred, averaged_samples):\n",
    "    gradients = K.gradients(y_pred, averaged_samples)[0]\n",
    "    gradients_sqr = K.square(gradients)\n",
    "    gradients_sqr_sum = K.sum(gradients_sqr, axis=np.arange(1, len(gradients_sqr.shape)))\n",
    "    gradient_l2_norm = K.sqrt(gradients_sqr_sum)\n",
    "    gradient_penalty = K.square(1 - gradient_l2_norm)\n",
    "    return K.mean(gradient_penalty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "725d1e78-5ccd-43d2-8c02-5ab951394ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "09a411d1-13a5-4c46-a084-a5906d4600c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator.trainable = False\n",
    "encoder.trainable = False\n",
    "\n",
    "x = tf.keras.Input(shape=input_shape)\n",
    "y = tf.keras.Input(shape=target_shape)\n",
    "z = tf.keras.Input(shape=(latent_dim, 1))\n",
    "\n",
    "x_ = generator(z)\n",
    "z_ = encoder(x)\n",
    "fake_x = critic_x(x_) # Fake\n",
    "valid_x = critic_x(y) # Truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c4749b5b-f050-42ef-b1db-bb92b2737240",
   "metadata": {},
   "outputs": [],
   "source": [
    "# interpolated_x = RandomWeightedAverage()([y, x_])\n",
    "alpha = K.random_uniform((64, 1, 1))\n",
    "interpolated_x = (alpha * [y, x_][0]) + ((1 - alpha) * [y, x_][1])\n",
    "validity_interpolated_x = critic_x(interpolated_x)\n",
    "partial_gp_loss_x = partial(_gradient_penalty_loss, averaged_samples=interpolated_x)\n",
    "partial_gp_loss_x.__name__ = 'gradient_penalty'\n",
    "critic_x_model = tf.keras.Model(inputs=[y, z], outputs=[valid_x, fake_x,validity_interpolated_x])\n",
    "critic_x_model.compile(loss=[_wasserstein_loss, _wasserstein_loss, partial_gp_loss_x], \n",
    "                       optimizer=optimizer, loss_weights=[1, 1, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ade19ad7-cafa-461d-945a-5c4a7596ad50",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_z = critic_z(z_)\n",
    "valid_z = critic_z(z)\n",
    "# interpolated_z = RandomWeightedAverage()([z, z_])\n",
    "alpha = K.random_uniform((64, 1, 1))\n",
    "interpolated_z = (alpha * [z, z_][0]) + ((1 - alpha) * [z, z_][1])\n",
    "validity_interpolated_z = critic_z(interpolated_z)\n",
    "partial_gp_loss_z = partial(_gradient_penalty_loss, averaged_samples=interpolated_z)\n",
    "partial_gp_loss_z.__name__ = 'gradient_penalty'\n",
    "critic_z_model = tf.keras.Model(inputs=[x, z], outputs=[valid_z, fake_z,validity_interpolated_z])\n",
    "critic_z_model.compile(loss=[_wasserstein_loss, _wasserstein_loss,\n",
    "                                  partial_gp_loss_z], optimizer=optimizer,\n",
    "                            loss_weights=[1, 1, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a005d68d-6cb1-4eaf-aeb2-b284d49c2a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "critic_x.trainable = False\n",
    "critic_z.trainable = False\n",
    "generator.trainable = True\n",
    "encoder.trainable = True\n",
    "\n",
    "z_gen = tf.keras.Input(shape=(latent_dim, 1))\n",
    "x_gen_ = generator(z_gen)\n",
    "x_gen = tf.keras.Input(shape=input_shape)\n",
    "z_gen_ = encoder(x_gen)\n",
    "x_gen_rec = generator(z_gen_)\n",
    "fake_gen_x = critic_x(x_gen_)\n",
    "fake_gen_z = critic_z(z_gen_)\n",
    "\n",
    "encoder_generator_model = tf.keras.Model([x_gen, z_gen], [fake_gen_x, fake_gen_z, x_gen_rec])\n",
    "encoder_generator_model.compile(loss=[_wasserstein_loss, _wasserstein_loss,'mse'], \n",
    "                                optimizer=optimizer,\n",
    "                                loss_weights=[1, 1, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8109a68-3727-400a-b89d-568506dd53c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/70, [Dx loss: [-4.24187    -8.015909    0.9574412   0.28165972]] [Dz loss: [ 4.5781426  -0.99709797  4.449582    0.11256589]] [G loss: [ 1.4436641  -0.94184685 -3.9820216   0.6367533 ]]\n",
      "Epoch: 2/70, [Dx loss: [-6.056184   -8.349213    1.2994711   0.09935593]] [Dz loss: [ 2.772599   -1.0329262   2.2865674   0.15189575]] [G loss: [ 5.2627206  -0.92800975  1.0047191   0.5186012 ]]\n",
      "Epoch: 3/70, [Dx loss: [-5.64261    -3.8386726  -2.7562244   0.09522863]] [Dz loss: [17.605806   -0.9500634  13.202464    0.53534067]] [G loss: [ 0.49423003  2.6964743  -7.4496913   0.52474475]]\n",
      "Epoch: 4/70, [Dx loss: [-5.664611   -6.413623   -0.14579882  0.08948103]] [Dz loss: [34.441914   -0.69006264 33.09275     0.20392092]] [G loss: [-2.0092443e+01 -2.2853605e-02 -2.4544413e+01  4.4748238e-01]]\n",
      "Epoch: 5/70, [Dx loss: [-5.907487   -7.4440904   0.5737573   0.09628473]] [Dz loss: [-4.9435816  -0.5135335  -5.332631    0.09025834]] [G loss: [18.284224   -0.63521993 14.582884    0.43365592]]\n",
      "Epoch: 6/70, [Dx loss: [-5.9923587  -7.9294486   0.99221593  0.0944874 ]] [Dz loss: [14.910268   -0.2530905  11.181135    0.39822254]] [G loss: [ 5.8890543 -0.9503405  2.5696268  0.4269768]]\n",
      "Epoch: 7/70, [Dx loss: [-6.0518785  -7.590725    0.5936054   0.09452419]] [Dz loss: [-85.564224     0.514079   -89.68434      0.36060473]] [G loss: [117.484245    -0.51975614 113.72446      0.42795408]]\n",
      "Epoch: 8/70, [Dx loss: [-6.2255135  -6.3625193  -0.79844654  0.09354533]] [Dz loss: [-139.30194      1.3162621 -163.2042       2.258601 ]] [G loss: [186.33731      0.93525296 181.14986      0.4252172 ]]\n",
      "Epoch: 9/70, [Dx loss: [-6.166456   -5.7924557  -1.3194481   0.09454468]] [Dz loss: [-51.328552     1.9675792  -61.45405      0.81579065]] [G loss: [78.25589     1.245218   72.785934    0.42247304]]\n",
      "Epoch: 10/70, [Dx loss: [-6.112611  -7.1822205  0.1190808  0.0950529]] [Dz loss: [-139.8262       2.5117614 -157.9429       1.5604928]] [G loss: [ 1.9535582e+02 -1.8883361e-01  1.9133687e+02  4.2077783e-01]]\n",
      "Epoch: 11/70, [Dx loss: [-6.0321937  -6.9962487   0.08647888  0.08775765]] [Dz loss: [ -93.21784      2.9881103 -129.24811      3.304213 ]] [G loss: [1.4552824e+02 4.8413947e-02 1.4125206e+02 4.2277747e-01]]\n",
      "Epoch: 12/70, [Dx loss: [-5.967155   -4.529391   -2.3254497   0.08876851]] [Dz loss: [ -95.206        3.2102885 -108.16122      0.9744937]] [G loss: [130.66187     2.4100113 123.99719     0.4254666]]\n",
      "Epoch: 13/70, [Dx loss: [-5.854188   -5.9254503  -0.7982801   0.08695432]] [Dz loss: [-175.23969     3.451516 -225.75993     4.706869]] [G loss: [238.05473      0.64702624 233.1815       0.4226203 ]]\n",
      "Epoch: 14/70, [Dx loss: [-5.7849703  -5.646702   -0.9681738   0.08299069]] [Dz loss: [-144.13034      3.5722096 -177.67435      2.997179 ]] [G loss: [197.63573     1.1184058 192.2637      0.425364 ]]\n",
      "Epoch: 15/70, [Dx loss: [-5.6637635  -5.581049   -0.9059906   0.08232759]] [Dz loss: [-208.50632      4.1947594 -282.08713      6.9386034]] [G loss: [304.52475      0.87660474 299.42798      0.4220156 ]]\n",
      "Epoch: 16/70, [Dx loss: [-5.551076   -4.858467   -1.4700588   0.07774492]] [Dz loss: [ -52.420197    4.485656 -142.48093     8.557505]] [G loss: [155.94012      1.490958   150.23192      0.42172405]]\n",
      "Epoch: 17/70, [Dx loss: [-5.441321   -4.8481517  -1.3678617   0.07746932]] [Dz loss: [-29.525295    4.5522127 -50.014706    1.5937202]] [G loss: [63.968338   1.4420843 58.32025    0.4206001]]\n",
      "Epoch: 18/70, [Dx loss: [-5.3467255  -4.216731   -1.8845043   0.07545091]] [Dz loss: [-103.198975     4.545041  -128.67387      2.0929866]] [G loss: [152.53023      1.8371878  146.46527      0.42277488]]\n",
      "Epoch: 19/70, [Dx loss: [-5.2495766  -4.2481623  -1.723099    0.07216834]] [Dz loss: [-143.69437      4.78506   -210.38693      6.1907554]] [G loss: [240.28102      1.7295179  234.34888      0.42026398]]\n",
      "Epoch: 20/70, [Dx loss: [-5.177684   -4.2816505  -1.6177219   0.07216886]] [Dz loss: [-110.47074      5.0007906 -196.64136      8.116982 ]] [G loss: [219.3199      1.6675074 213.48105     0.4171339]]\n",
      "Epoch: 21/70, [Dx loss: [-5.116595   -4.0157595  -1.8188884   0.07180528]] [Dz loss: [ -94.36147     4.933806 -161.33711     6.204181]] [G loss: [171.88643      1.8437473  165.8373       0.42053604]]\n",
      "Epoch: 22/70, [Dx loss: [-5.0920362  -4.288577   -1.5178263   0.07143666]] [Dz loss: [ -75.73033      5.0617113 -136.38412      5.559209 ]] [G loss: [150.56602      1.7689414  144.58272      0.42143598]]\n",
      "Epoch: 23/70, [Dx loss: [-5.0466948  -3.5325165  -2.2223344   0.07081561]] [Dz loss: [-49.292004    5.0747848 -99.92819     4.556141 ]] [G loss: [109.846405     1.9465947  103.67928      0.42205203]]\n",
      "Epoch: 24/70, [Dx loss: [-4.932335   -5.019742   -0.5830804   0.06704871]] [Dz loss: [-32.816647    4.9762154 -72.33921     3.4546363]] [G loss: [82.188995    0.86077344 77.13577     0.419244  ]]\n",
      "Epoch: 25/70, [Dx loss: [-4.794075   -1.0930548  -4.34535     0.06443299]] [Dz loss: [-39.05166     4.8958344 -68.293045    2.4345565]] [G loss: [81.42053     4.416536   72.76335     0.42406482]]\n",
      "Epoch: 26/70, [Dx loss: [-4.636008   -1.3558004  -3.898309    0.06181021]] [Dz loss: [-53.809986    4.824502  -84.72213     2.6087642]] [G loss: [97.31436     3.89532    89.19966     0.42193794]]\n",
      "Epoch: 27/70, [Dx loss: [-4.4535804  -2.1201293  -2.9405673   0.06071158]] [Dz loss: [-53.45647    4.873425 -88.9975     3.066761]] [G loss: [100.9503       3.0463567   93.69651      0.42074442]]\n",
      "Epoch: 28/70, [Dx loss: [-4.1018248   0.22369592 -4.8196077   0.04940864]] [Dz loss: [-38.343502    4.757125  -71.493416    2.8392797]] [G loss: [82.05197     4.8448577  72.9984      0.42087203]]\n",
      "Epoch: 29/70, [Dx loss: [-3.61549     0.2718688  -4.2801223   0.03927637]] [Dz loss: [-29.731464    4.6121507 -58.486046    2.4142432]] [G loss: [68.75013     4.3860917  60.019367    0.43446723]]\n",
      "Epoch: 30/70, [Dx loss: [-3.405944    1.2382308  -5.0111723   0.03669975]] [Dz loss: [-20.192547    4.3967066 -49.013393    2.4424138]] [G loss: [61.03864     5.068474   51.64023     0.43299383]]\n",
      "Epoch: 31/70, [Dx loss: [-3.317984    2.2553577  -5.9206557   0.03473138]] [Dz loss: [ -8.468819    4.398251  -34.905296    2.2038236]] [G loss: [46.286556    6.0172515  35.89593     0.43733674]]\n",
      "Epoch: 32/70, [Dx loss: [-3.4032478   2.3095775  -6.072248    0.03594221]] [Dz loss: [  1.4145631   4.06999   -16.971773    1.4316347]] [G loss: [28.182192    6.0670485  17.73319     0.43819505]]\n",
      "Epoch: 33/70, [Dx loss: [-2.9665873   1.7832623  -5.056383    0.03065335]] [Dz loss: [ -0.65878874   3.9472408  -13.587442     0.8981415 ]] [G loss: [24.21073     5.004897   14.861651    0.43441844]]\n",
      "Epoch: 34/70, [Dx loss: [-2.2936056   0.6769992  -3.1939175   0.02233129]] [Dz loss: [ -1.7791779    3.7822902  -11.793535     0.62320673]] [G loss: [20.112179   3.1268442 12.61026    0.4375074]]\n",
      "Epoch: 35/70, [Dx loss: [-1.7017834   0.24118178 -2.1070666   0.01641014]] [Dz loss: [ -5.513944    3.6391342 -13.951719    0.4798643]] [G loss: [21.150166    2.2184467  14.577404    0.43543142]]\n",
      "Epoch: 36/70, [Dx loss: [-1.8020201  -0.18952104 -1.8246425   0.02121436]] [Dz loss: [ -8.965202    3.5237164 -16.68972     0.4200799]] [G loss: [23.212494    1.5847108  17.206099    0.44216844]]\n",
      "Epoch: 37/70, [Dx loss: [-1.5195516  -2.2578444   0.5377245   0.02005679]] [Dz loss: [ -9.147845     3.4698746  -17.291122     0.46734008]] [G loss: [21.9029      0.02678671 17.518728    0.43573844]]\n",
      "Epoch: 38/70, [Dx loss: [-1.5399673   5.852531   -7.5356283   0.01431302]] [Dz loss: [ -6.324682    3.3329282 -14.09403     0.4436419]] [G loss: [26.047125    7.5883174  14.011496    0.44473135]]\n",
      "Epoch: 39/70, [Dx loss: [-1.6655674  -0.2145231  -1.6873605   0.02363162]] [Dz loss: [-2.3722236   3.2667973  -9.658141    0.40191212]] [G loss: [15.718957    1.5157976   9.782779    0.44203806]]\n",
      "Epoch: 40/70, [Dx loss: [-1.4129903   5.302129   -6.8680243   0.01529046]] [Dz loss: [ 1.0997467   3.1435714  -6.039879    0.39960548]] [G loss: [18.266005    7.463056    6.289239    0.45137087]]\n",
      "Epoch: 41/70, [Dx loss: [-1.5240633   2.6398044  -4.3292017   0.01653342]] [Dz loss: [ 3.5459943  2.888462  -3.354613   0.4012146]] [G loss: [11.54341    3.638368   3.5772483  0.4327795]]\n",
      "Epoch: 42/70, [Dx loss: [-1.3964821  -2.8112018   1.2579094   0.01568104]] [Dz loss: [ 2.3119144  2.6591322 -3.360101   0.3012884]] [G loss: [ 6.6006217  -1.2197828   3.5039      0.43165043]]\n",
      "Epoch: 43/70, [Dx loss: [-1.2640635   0.69255054 -2.0793185   0.01227044]] [Dz loss: [ 0.60722     2.5115886  -4.9492617   0.30448928]] [G loss: [12.107439    2.54773     5.2595305   0.43001798]]\n",
      "Epoch: 44/70, [Dx loss: [-1.5835462   6.3922296  -8.120491    0.01447157]] [Dz loss: [-0.7258383  2.3905098 -5.914744   0.2798395]] [G loss: [18.401531    8.099222    5.992227    0.43100837]]\n",
      "Epoch: 45/70, [Dx loss: [-1.5369492   3.1523714  -4.850357    0.01610355]] [Dz loss: [-0.81711596  2.3225749  -6.1261277   0.29864365]] [G loss: [15.69672     4.9787693   6.29823     0.44197208]]\n",
      "Epoch: 46/70, [Dx loss: [-1.415757    4.7755876  -6.3411016   0.01497564]] [Dz loss: [-0.29817528  2.2584348  -5.540343    0.29837337]] [G loss: [16.334883   6.280406   5.6281114  0.4426366]]\n",
      "Epoch: 47/70, [Dx loss: [-1.391339    4.8671227  -6.411598    0.01531357]] [Dz loss: [ 0.06093128  2.0864387  -4.8546624   0.2829155 ]] [G loss: [16.072441    6.6657667   4.923042    0.44836307]]\n",
      "Epoch: 48/70, [Dx loss: [-1.7192266   5.813714   -7.7049193   0.01719785]] [Dz loss: [ 1.669336    1.9740212  -3.5984466   0.32937616]] [G loss: [15.715898    7.6052275   3.7170372   0.43936324]]\n"
     ]
    }
   ],
   "source": [
    "fake = np.ones((batch_size, 1))\n",
    "valid = -np.ones((batch_size, 1))\n",
    "delta = np.ones((batch_size, 1))\n",
    "\n",
    "indices = np.arange(X.shape[0])\n",
    "for epoch in range(1, epochs + 1):\n",
    "    np.random.shuffle(indices)\n",
    "    X_ = X[indices]\n",
    "    y_ = target[indices]\n",
    "\n",
    "    epoch_g_loss = []\n",
    "    epoch_cx_loss = []\n",
    "    epoch_cz_loss = []\n",
    "\n",
    "    minibatches_size = batch_size * iterations_critic\n",
    "    num_minibatches = int(X_.shape[0] // minibatches_size)\n",
    "\n",
    "    for i in range(num_minibatches):\n",
    "        minibatch = X_[i * minibatches_size: (i + 1) * minibatches_size]\n",
    "        y_minibatch = y_[i * minibatches_size: (i + 1) * minibatches_size]\n",
    "\n",
    "        for j in range(iterations_critic):\n",
    "            x = minibatch[j * batch_size: (j + 1) * batch_size]\n",
    "            y = y_minibatch[j * batch_size: (j + 1) * batch_size]\n",
    "            z = np.random.normal(size=(batch_size, latent_dim, 1))\n",
    "            epoch_cx_loss.append(\n",
    "                critic_x_model.train_on_batch([y, z], [valid, fake, delta]))\n",
    "            epoch_cz_loss.append(\n",
    "                critic_z_model.train_on_batch([x, z], [valid, fake, delta]))\n",
    "\n",
    "        epoch_g_loss.append(\n",
    "            encoder_generator_model.train_on_batch([x, z], [valid, valid, y]))\n",
    "\n",
    "    cx_loss = np.mean(np.array(epoch_cx_loss), axis=0)\n",
    "    cz_loss = np.mean(np.array(epoch_cz_loss), axis=0)\n",
    "    g_loss = np.mean(np.array(epoch_g_loss), axis=0)\n",
    "    print('Epoch: {}/{}, [Dx loss: {}] [Dz loss: {}] [G loss: {}]'.format(\n",
    "        epoch, epochs, cx_loss, cz_loss, g_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60954f6e-b693-4839-8b7d-7f968ac83e73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
