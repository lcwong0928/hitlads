{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1364d5aa-61be-4ed1-bba6-88710327e70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from orion.data import load_signal\n",
    "from orion import Orion\n",
    "from orion.data import load_anomalies\n",
    "\n",
    "from mlprimitives.custom.timeseries_preprocessing import time_segments_aggregate\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from mlprimitives.custom.timeseries_preprocessing import rolling_window_sequences\n",
    "from orion.primitives.timeseries_preprocessing import slice_array_by_dims\n",
    "from mlprimitives import load_primitive\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from pandas import Timestamp\n",
    "import pickle\n",
    "import json\n",
    "import glob\n",
    "\n",
    "\n",
    "cwd = os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a1fc25-c35b-4511-a5e0-b7d05981b93b",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "\n",
    "Input - timestamp, values, exogenous variables\n",
    "\n",
    "Output - start, end anomalous intervals, severity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8dbd0c7-da3e-4378-af78-1a0fc8c85b84",
   "metadata": {},
   "source": [
    "## Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e185f5e-1b7e-4e54-9474-017c73d37938",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2818, 26), (7331, 26))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = load_signal('multivariate/S-1-train')\n",
    "X_test = load_signal('multivariate/S-1-test')\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac0ceadf-0a66-4783-90e0-661e42dc5868",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'processed/SWaT.pickle'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/_5/f7yzqnxs6694l3c_yk9mjpzr0000gn/T/ipykernel_8176/498995151.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'processed/SWaT.pickle'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0minterval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m25\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m60\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'processed/SWaT.pickle'"
     ]
    }
   ],
   "source": [
    "with open('processed/SWaT.pickle', 'rb') as f:\n",
    "    dataset = pickle.load(f)\n",
    "    \n",
    "interval = 25 * 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "761fe22b-fafd-46bb-8883-424d87220ea7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lcwong/opt/anaconda3/envs/orion-env/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "split = len(dataset['X']) // 3\n",
    "X_train = dataset['X'][:split]\n",
    "X_train['timestamp'] = X_train.index\n",
    "y_train = dataset['y'][:split]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca5d94f-8bba-471a-80ef-2f8beb2bb76c",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87c244ca-7f39-4b39-866b-a4b06a02b1e1",
   "metadata": {},
   "outputs": [
    {
     "ename": "VersionConflict",
     "evalue": "(numpy 1.21.2 (/Users/lcwong/opt/anaconda3/envs/orion-env/lib/python3.7/site-packages), Requirement.parse('numpy<1.17,>=1.15.4'))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mVersionConflict\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/_5/f7yzqnxs6694l3c_yk9mjpzr0000gn/T/ipykernel_85110/3945788991.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;34m\"method\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"mean\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m }\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mprimitive\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_primitive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mlprimitives.custom.timeseries_preprocessing.time_segments_aggregate'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marguments\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprimitive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/orion-env/lib/python3.7/site-packages/mlprimitives/__init__.py\u001b[0m in \u001b[0;36mload_primitive\u001b[0;34m(primitive, arguments)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0marguments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marguments\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mMLBlock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprimitive\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0marguments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/envs/orion-env/lib/python3.7/site-packages/mlblocks/mlblock.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, primitive, **kwargs)\u001b[0m\n\u001b[1;32m    157\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprimitive\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprimitive\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m             \u001b[0mprimitive\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_primitive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprimitive\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprimitive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/orion-env/lib/python3.7/site-packages/mlblocks/discovery.py\u001b[0m in \u001b[0;36mload_primitive\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[0mprimitive\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_PRIMITIVES\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mprimitive\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0mprimitive\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_primitives_paths\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mprimitive\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Unknown primitive: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/orion-env/lib/python3.7/site-packages/mlblocks/discovery.py\u001b[0m in \u001b[0;36mget_primitives_paths\u001b[0;34m()\u001b[0m\n\u001b[1;32m    170\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0mfolders\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m     \"\"\"\n\u001b[0;32m--> 172\u001b[0;31m     \u001b[0mpaths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_load_entry_points\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'primitives'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0m_load_entry_points\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'jsons_path'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'mlprimitives'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_PRIMITIVES_PATHS\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpaths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/orion-env/lib/python3.7/site-packages/mlblocks/discovery.py\u001b[0m in \u001b[0;36m_load_entry_points\u001b[0;34m(entry_point_name, entry_point_group)\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mentry_point\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentry_points\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mentry_point\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mentry_point_name\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m             \u001b[0mpaths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mentry_point\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpaths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m                 \u001b[0mlookup_paths\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpaths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/orion-env/lib/python3.7/site-packages/pkg_resources/__init__.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self, require, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2447\u001b[0m             )\n\u001b[1;32m   2448\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrequire\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2449\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2450\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2451\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/orion-env/lib/python3.7/site-packages/pkg_resources/__init__.py\u001b[0m in \u001b[0;36mrequire\u001b[0;34m(self, env, installer)\u001b[0m\n\u001b[1;32m   2470\u001b[0m         \u001b[0;31m# requirements for that extra are purely optional and skip over them.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2471\u001b[0m         \u001b[0mreqs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextras\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2472\u001b[0;31m         \u001b[0mitems\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mworking_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreqs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstaller\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextras\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextras\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2473\u001b[0m         \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworking_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/orion-env/lib/python3.7/site-packages/pkg_resources/__init__.py\u001b[0m in \u001b[0;36mresolve\u001b[0;34m(self, requirements, env, installer, replace_conflicting, extras)\u001b[0m\n\u001b[1;32m    775\u001b[0m                 \u001b[0;31m# Oops, the \"best\" so far conflicts with a dependency\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m                 \u001b[0mdependent_req\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequired_by\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 777\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mVersionConflict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdependent_req\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    778\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m             \u001b[0;31m# push the new requirements onto the stack\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mVersionConflict\u001b[0m: (numpy 1.21.2 (/Users/lcwong/opt/anaconda3/envs/orion-env/lib/python3.7/site-packages), Requirement.parse('numpy<1.17,>=1.15.4'))"
     ]
    }
   ],
   "source": [
    "# Creates an equi-spaced time series by aggregating values over fixed specified interval\n",
    "# Food for thought, we don't need to bin it by set intervals?\n",
    "params = {\n",
    "    \"time_column\": \"timestamp\", \n",
    "    \"interval\": 21600, \n",
    "    # \"interval\": interval,\n",
    "    \"method\": \"mean\"\n",
    "}\n",
    "primitive = load_primitive('mlprimitives.custom.timeseries_preprocessing.time_segments_aggregate', arguments=params)\n",
    "X, index = primitive.produce(X=X_train)\n",
    "\n",
    "X.shape, index.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5730c044-11af-4df7-84d0-e3b5ed3b8995",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/_5/f7yzqnxs6694l3c_yk9mjpzr0000gn/T/ipykernel_85110/1986250591.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# This primitive is an imputation transformer for filling missing values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m params = {\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;34m'X'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m }\n\u001b[1;32m      5\u001b[0m \u001b[0mprimitive\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_primitive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'sklearn.impute.SimpleImputer'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marguments\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "# This primitive is an imputation transformer for filling missing values\n",
    "params = {\n",
    "    'X': X\n",
    "}\n",
    "primitive = load_primitive('sklearn.impute.SimpleImputer', arguments=params)\n",
    "primitive.fit()\n",
    "X = primitive.produce(X=X)\n",
    "\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eec9b1a1-c67d-4ecd-ade5-2dcc4f761bb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2818, 25)\n"
     ]
    }
   ],
   "source": [
    "# This primitive transforms features by scaling each feature to a given range\n",
    "params = {\n",
    "    \"feature_range\": [-1, 1], \n",
    "    'X': X,\n",
    "}\n",
    "primitive = load_primitive('sklearn.preprocessing.MinMaxScaler', arguments=params)\n",
    "primitive.fit()\n",
    "X = primitive.produce(X=X)\n",
    "\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6dfa9296-2e83-4bd4-b672-437ec98ae369",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2718, 100, 25), (2718, 1), (2718,), (2718,))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Uses a rolling window approach to create the sub-sequences out of time series data\n",
    "params = {\n",
    "    \"target_column\": 0, \n",
    "    \"window_size\": 100, \n",
    "    'target_size': 1, \n",
    "    'step_size': 1\n",
    "}\n",
    "primitive = load_primitive('mlprimitives.custom.timeseries_preprocessing.rolling_window_sequences',\n",
    "                           arguments=params)\n",
    "X, y, index, target_index = primitive.produce(X=X, index=index)\n",
    "\n",
    "\n",
    "# Target / target size is the next interval that is trying to predict.\n",
    "# Index is the start of the interval\n",
    "X.shape, y.shape, index.shape, target_index.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d7704c91-6f0a-4f88-b3c5-2a7bfebf1f04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2718, 100, 25), (2718, 100, 1))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Target\n",
    "params = {\n",
    "    \"target_index\": 0, \n",
    "    \"axis\": 2\n",
    "}\n",
    "primitive = load_primitive('orion.primitives.timeseries_preprocessing.slice_array_by_dims',\n",
    "                           arguments=params)\n",
    "y = primitive.produce(X=X)\n",
    "\n",
    "# Trying to predict the target sequence which is the first column of X\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb954a62-2c20-4305-a371-986f4534cbf8",
   "metadata": {},
   "source": [
    "## Saving the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4f5be7b2-7984-4e26-a275-f72127523f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('processed/data/X', X)\n",
    "np.save('processed/data/y', y)\n",
    "np.save('processed/data/index', index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a75d82-ea89-448f-b443-663deab86798",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaac559f-0e3a-429b-ad29-4b49fad72876",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a5f9ff44-ded8-4d3b-b9d0-bd00c4f59dda",
   "metadata": {},
   "source": [
    "# NASA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6bdaf672-e80a-4ded-b7e2-785d6168b36d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chan_id</th>\n",
       "      <th>spacecraft</th>\n",
       "      <th>anomaly_sequences</th>\n",
       "      <th>class</th>\n",
       "      <th>num_values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P-1</td>\n",
       "      <td>SMAP</td>\n",
       "      <td>[[2149, 2349], [4536, 4844], [3539, 3779]]</td>\n",
       "      <td>[contextual, contextual, contextual]</td>\n",
       "      <td>8505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S-1</td>\n",
       "      <td>SMAP</td>\n",
       "      <td>[[5300, 5747]]</td>\n",
       "      <td>[point]</td>\n",
       "      <td>7331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>E-1</td>\n",
       "      <td>SMAP</td>\n",
       "      <td>[[5000, 5030], [5610, 6086]]</td>\n",
       "      <td>[contextual, contextual]</td>\n",
       "      <td>8516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>E-2</td>\n",
       "      <td>SMAP</td>\n",
       "      <td>[[5598, 6995]]</td>\n",
       "      <td>[point]</td>\n",
       "      <td>8532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>E-3</td>\n",
       "      <td>SMAP</td>\n",
       "      <td>[[5094, 8306]]</td>\n",
       "      <td>[point]</td>\n",
       "      <td>8307</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  chan_id spacecraft                           anomaly_sequences  \\\n",
       "0     P-1       SMAP  [[2149, 2349], [4536, 4844], [3539, 3779]]   \n",
       "1     S-1       SMAP                              [[5300, 5747]]   \n",
       "2     E-1       SMAP                [[5000, 5030], [5610, 6086]]   \n",
       "3     E-2       SMAP                              [[5598, 6995]]   \n",
       "4     E-3       SMAP                              [[5094, 8306]]   \n",
       "\n",
       "                                  class  num_values  \n",
       "0  [contextual, contextual, contextual]        8505  \n",
       "1                               [point]        7331  \n",
       "2              [contextual, contextual]        8516  \n",
       "3                               [point]        8532  \n",
       "4                               [point]        8307  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('datasets/NASA/source/labeled_anomalies.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "173b51ab-61cf-4718-9075-bc3a9de2e641",
   "metadata": {},
   "outputs": [],
   "source": [
    "MSL_dataset = {\n",
    "    'train': [],\n",
    "    'test': [],\n",
    "    'anomaly': [],\n",
    "}\n",
    "\n",
    "SMAP_dataset = {\n",
    "    'train': [],\n",
    "    'test': [],\n",
    "    'anomaly': [],\n",
    "}\n",
    "\n",
    "for split in ['train', 'test']:\n",
    "\n",
    "    for filepath in glob.glob(f'datasets/NASA/source/{split}/**.npy'):\n",
    "        filename = os.path.basename(filepath)\n",
    "        signal, _ = filename.split('.')\n",
    "\n",
    "        info = df[df.chan_id == signal]\n",
    "    \n",
    "        if len(info) > 0:\n",
    "            dataset = pd.DataFrame(np.load(filepath))\n",
    "            dataset = dataset.reset_index() \n",
    "            \n",
    "            # Metadata\n",
    "            original_columns = dataset.columns\n",
    "            dataset['source'] = 'NASA'\n",
    "            dataset['name'] = info['spacecraft'].iloc[0]\n",
    "            dataset['signal'] = signal\n",
    "            \n",
    "            # Anomaly points\n",
    "            anomaly_points = [0] * len(dataset)\n",
    "            if split == 'test':\n",
    "                for interval in eval(info.anomaly_sequences.iloc[0]):\n",
    "                    for i in range(interval[0], interval[1]):\n",
    "                        if i < len(anomaly_points):\n",
    "                            anomaly_points[i] = 1\n",
    "            dataset['anomaly'] = anomaly_points\n",
    "            dataset = dataset[list(dataset.columns[-4:]) + list(dataset.columns[:-4])]\n",
    "            \n",
    "            # Anomaly intervals\n",
    "            anomaly_interval = pd.DataFrame(eval(info.anomaly_sequences.iloc[0]))\n",
    "            anomaly_interval.columns = ['start', 'end']\n",
    "            anomaly_interval['source'] = 'NASA'\n",
    "            anomaly_interval['name'] = name\n",
    "            anomaly_interval['signal'] = signal\n",
    "            anomaly_interval = anomaly_interval[list(anomaly_interval.columns[-3:]) + list(anomaly_interval.columns[:-3])]\n",
    "\n",
    "            if info['spacecraft'].iloc[0] == 'SMAP':\n",
    "                SMAP_dataset[split].append(dataset)\n",
    "                if split == 'test':\n",
    "                    SMAP_dataset['anomaly'].append(anomaly_interval)\n",
    "            elif info['spacecraft'].iloc[0] == 'MSL':\n",
    "                MSL_dataset[split].append(dataset)\n",
    "                if split == 'test':\n",
    "                    MSL_dataset['anomaly'].append(anomaly_interval)\n",
    "\n",
    "SMAP_dataset['train'] = pd.concat(SMAP_dataset['train'])\n",
    "SMAP_dataset['test'] = pd.concat(SMAP_dataset['test'])\n",
    "SMAP_dataset['anomaly'] = pd.concat(SMAP_dataset['anomaly']).drop_duplicates()\n",
    "MSL_dataset['train'] = pd.concat(MSL_dataset['train'])\n",
    "MSL_dataset['test'] = pd.concat(MSL_dataset['test'])\n",
    "MSL_dataset['anomaly'] = pd.concat(MSL_dataset['anomaly']).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "b0bc368f-f7f0-4a6e-b75d-598eea7e5c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_summary(train, test, anomaly):\n",
    "    print('# channels', len(train.columns[5:]))\n",
    "    print('# contextual', len(anomaly))\n",
    "    print('# Anomaly', train.anomaly.value_counts().get(1, 0) + test.anomaly.value_counts().get(1, 0))\n",
    "    print('# Data', len(train) + len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "ca675359-738e-4b0d-aeab-da8dcf706748",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>name</th>\n",
       "      <th>signal</th>\n",
       "      <th>anomaly</th>\n",
       "      <th>index</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>...</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NASA</td>\n",
       "      <td>SMAP</td>\n",
       "      <td>P-7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.450982</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NASA</td>\n",
       "      <td>SMAP</td>\n",
       "      <td>P-7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.411767</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NASA</td>\n",
       "      <td>SMAP</td>\n",
       "      <td>P-7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.411767</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NASA</td>\n",
       "      <td>SMAP</td>\n",
       "      <td>P-7</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.372547</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NASA</td>\n",
       "      <td>SMAP</td>\n",
       "      <td>P-7</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.333332</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  source  name signal  anomaly  index         0    1    2    3    4  ...   15  \\\n",
       "0   NASA  SMAP    P-7        0      0  0.450982  0.0  0.0  0.0  0.0  ...  0.0   \n",
       "1   NASA  SMAP    P-7        0      1  0.411767  0.0  0.0  0.0  0.0  ...  0.0   \n",
       "2   NASA  SMAP    P-7        0      2  0.411767  0.0  0.0  0.0  0.0  ...  0.0   \n",
       "3   NASA  SMAP    P-7        0      3  0.372547  0.0  0.0  0.0  0.0  ...  0.0   \n",
       "4   NASA  SMAP    P-7        0      4  0.333332  0.0  0.0  0.0  0.0  ...  0.0   \n",
       "\n",
       "    16   17   18   19   20   21   22   23   24  \n",
       "0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SMAP_dataset['train'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "a6014abf-1938-4bd5-ac93-46e6a813924f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>name</th>\n",
       "      <th>signal</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NASA</td>\n",
       "      <td>SMAP</td>\n",
       "      <td>P-7</td>\n",
       "      <td>4950</td>\n",
       "      <td>6600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NASA</td>\n",
       "      <td>SMAP</td>\n",
       "      <td>E-8</td>\n",
       "      <td>5400</td>\n",
       "      <td>6022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NASA</td>\n",
       "      <td>SMAP</td>\n",
       "      <td>T-3</td>\n",
       "      <td>2098</td>\n",
       "      <td>2180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NASA</td>\n",
       "      <td>SMAP</td>\n",
       "      <td>T-3</td>\n",
       "      <td>5200</td>\n",
       "      <td>5300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NASA</td>\n",
       "      <td>SMAP</td>\n",
       "      <td>T-2</td>\n",
       "      <td>6840</td>\n",
       "      <td>8624</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  source  name signal  start   end\n",
       "0   NASA  SMAP    P-7   4950  6600\n",
       "0   NASA  SMAP    E-8   5400  6022\n",
       "0   NASA  SMAP    T-3   2098  2180\n",
       "1   NASA  SMAP    T-3   5200  5300\n",
       "0   NASA  SMAP    T-2   6840  8624"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SMAP_dataset['anomaly'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "8641ebf0-c0bc-4416-ad93-f5085f2600fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# channels 25\n",
      "# contextual 68\n",
      "# Anomaly 55854\n",
      "# Data 573830\n"
     ]
    }
   ],
   "source": [
    "print_summary(SMAP_dataset['train'], SMAP_dataset['test'], SMAP_dataset['anomaly'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "7d26fdbf-7225-4a7e-8fb2-5b5e3fae6246",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# channels 55\n",
      "# contextual 36\n",
      "# Anomaly 7730\n",
      "# Data 132046\n"
     ]
    }
   ],
   "source": [
    "print_summary(MSL_dataset['train'], MSL_dataset['test'], MSL_dataset['anomaly'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "addeb65c-3a1c-4594-9736-896a45d7bbc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('processed/datasets/MSL.pickle', 'wb') as f:\n",
    "    pickle.dump(MSL_dataset, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "a641c281-1d7a-45a0-988f-b58b2efc4e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('processed/datasets/SMAP.pickle', 'wb') as f:\n",
    "    pickle.dump(SMAP_dataset, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a70090cc-d937-454d-9bd9-ae1c2205294e",
   "metadata": {},
   "source": [
    "# SWaT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "33e9c404-4c4c-401f-bb76-8d540e6df15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('datasets/SWaT/A1_A2_2015_dec/SWaT_Dataset_Attack_v0.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "1f152581-7afd-4b64-9739-220d72cea39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = df.iloc[0]\n",
    "df = df.iloc[1:]\n",
    "df = df.set_index(pd.to_datetime(df[' Timestamp'], dayfirst=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "613a9f52-bbce-420f-b852-e49b382fabf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>FIT101</th>\n",
       "      <th>LIT101</th>\n",
       "      <th>MV101</th>\n",
       "      <th>P101</th>\n",
       "      <th>P102</th>\n",
       "      <th>AIT201</th>\n",
       "      <th>AIT202</th>\n",
       "      <th>AIT203</th>\n",
       "      <th>FIT201</th>\n",
       "      <th>...</th>\n",
       "      <th>P501</th>\n",
       "      <th>P502</th>\n",
       "      <th>PIT501</th>\n",
       "      <th>PIT502</th>\n",
       "      <th>PIT503</th>\n",
       "      <th>FIT601</th>\n",
       "      <th>P601</th>\n",
       "      <th>P602</th>\n",
       "      <th>P603</th>\n",
       "      <th>Normal/Attack</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-12-28 10:00:00</th>\n",
       "      <td>28/12/2015 10:00:00 AM</td>\n",
       "      <td>2.42706</td>\n",
       "      <td>522.847</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>262.016</td>\n",
       "      <td>8.39644</td>\n",
       "      <td>328.634</td>\n",
       "      <td>2.44539</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>250.865</td>\n",
       "      <td>1.64995</td>\n",
       "      <td>189.599</td>\n",
       "      <td>0.000128152</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-28 10:00:01</th>\n",
       "      <td>28/12/2015 10:00:01 AM</td>\n",
       "      <td>2.44627</td>\n",
       "      <td>522.886</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>262.016</td>\n",
       "      <td>8.39644</td>\n",
       "      <td>328.634</td>\n",
       "      <td>2.44539</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>250.865</td>\n",
       "      <td>1.64995</td>\n",
       "      <td>189.679</td>\n",
       "      <td>0.000128152</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-28 10:00:02</th>\n",
       "      <td>28/12/2015 10:00:02 AM</td>\n",
       "      <td>2.48919</td>\n",
       "      <td>522.847</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>262.016</td>\n",
       "      <td>8.39451</td>\n",
       "      <td>328.634</td>\n",
       "      <td>2.44232</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>250.881</td>\n",
       "      <td>1.64995</td>\n",
       "      <td>189.679</td>\n",
       "      <td>0.000128152</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-28 10:00:03</th>\n",
       "      <td>28/12/2015 10:00:03 AM</td>\n",
       "      <td>2.53435</td>\n",
       "      <td>522.965</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>262.016</td>\n",
       "      <td>8.39451</td>\n",
       "      <td>328.634</td>\n",
       "      <td>2.44232</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>250.881</td>\n",
       "      <td>1.64995</td>\n",
       "      <td>189.615</td>\n",
       "      <td>0.000128152</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-28 10:00:04</th>\n",
       "      <td>28/12/2015 10:00:04 AM</td>\n",
       "      <td>2.56926</td>\n",
       "      <td>523.475</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>262.016</td>\n",
       "      <td>8.39451</td>\n",
       "      <td>328.634</td>\n",
       "      <td>2.44308</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>250.881</td>\n",
       "      <td>1.64995</td>\n",
       "      <td>189.503</td>\n",
       "      <td>0.000128152</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "0                                  Timestamp   FIT101   LIT101  MV101 P101  \\\n",
       " Timestamp                                                                   \n",
       "2015-12-28 10:00:00   28/12/2015 10:00:00 AM  2.42706  522.847      2    2   \n",
       "2015-12-28 10:00:01   28/12/2015 10:00:01 AM  2.44627  522.886      2    2   \n",
       "2015-12-28 10:00:02   28/12/2015 10:00:02 AM  2.48919  522.847      2    2   \n",
       "2015-12-28 10:00:03   28/12/2015 10:00:03 AM  2.53435  522.965      2    2   \n",
       "2015-12-28 10:00:04   28/12/2015 10:00:04 AM  2.56926  523.475      2    2   \n",
       "\n",
       "0                   P102   AIT201   AIT202   AIT203   FIT201  ... P501 P502  \\\n",
       " Timestamp                                                    ...             \n",
       "2015-12-28 10:00:00    1  262.016  8.39644  328.634  2.44539  ...    2    1   \n",
       "2015-12-28 10:00:01    1  262.016  8.39644  328.634  2.44539  ...    2    1   \n",
       "2015-12-28 10:00:02    1  262.016  8.39451  328.634  2.44232  ...    2    1   \n",
       "2015-12-28 10:00:03    1  262.016  8.39451  328.634  2.44232  ...    2    1   \n",
       "2015-12-28 10:00:04    1  262.016  8.39451  328.634  2.44308  ...    2    1   \n",
       "\n",
       "0                     PIT501   PIT502   PIT503       FIT601 P601 P602 P603  \\\n",
       " Timestamp                                                                   \n",
       "2015-12-28 10:00:00  250.865  1.64995  189.599  0.000128152    1    1    1   \n",
       "2015-12-28 10:00:01  250.865  1.64995  189.679  0.000128152    1    1    1   \n",
       "2015-12-28 10:00:02  250.881  1.64995  189.679  0.000128152    1    1    1   \n",
       "2015-12-28 10:00:03  250.881  1.64995  189.615  0.000128152    1    1    1   \n",
       "2015-12-28 10:00:04  250.881  1.64995  189.503  0.000128152    1    1    1   \n",
       "\n",
       "0                   Normal/Attack  \n",
       " Timestamp                         \n",
       "2015-12-28 10:00:00        Normal  \n",
       "2015-12-28 10:00:01        Normal  \n",
       "2015-12-28 10:00:02        Normal  \n",
       "2015-12-28 10:00:03        Normal  \n",
       "2015-12-28 10:00:04        Normal  \n",
       "\n",
       "[5 rows x 53 columns]"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "c6509cd7-c647-4925-a564-523ed8f9c4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_abnormalities = \"\"\"\n",
    "28/12/2015 10:29:14\t10:44:53\n",
    "28/12/2015 10:51:08\t10:58:30 \n",
    "28/12/2015 11:22:00\t11:28:22\n",
    "28/12/2015 11:47:39\t11:54:08\n",
    "28/12/2015 12:00:55\t12:04:10\n",
    "28/12/2015 12:08:25\t12:15:33\n",
    "28/12/2015 13:10:10\t13:26:13\n",
    "28/12/2015 14:16:20\t14:19:00\n",
    "28/12/2015 14:19:00\t14:28:20\n",
    "29/12/2015 11:11:25\t11:15:17\n",
    "29/12/2015 11:35:40\t11:42:50\n",
    "29/12/2015 11:57:25\t12:02:00\n",
    "29/12/2015 14:38:12\t14:50:08\n",
    "29/12/2015 18:10:43\t18:15:01\n",
    "29/12/2015 18:15:43\t18:22:17\n",
    "29/12/2015 18:30:00\t18:42:00\n",
    "29/12/2015 22:55:18\t23:03:00\n",
    "30/12/2015 01:42:34\t1:54:10\n",
    "30/12/2015 09:51:08\t9:56:28\n",
    "30/12/2015 10:01:50\t10:12:01\n",
    "30/12/2015 17:04:56\t17:29:00\n",
    "31/12/2015 01:17:08\t1:45:18\n",
    "31/12/2015 01:45:19\t11:15:27\n",
    "31/12/2015 15:32:00\t15:34:00\n",
    "31/12/2015 15:47:40\t16:07:10\n",
    "31/12/2015 22:05:34\t22:11:40\n",
    "1/01/2016 10:36:00\t10:46:00\n",
    "1/01/2016 14:21:12\t14:28:35\n",
    "1/01/2016 17:12:40\t17:14:20\n",
    "1/01/2016 17:18:56\t17:26:56\n",
    "1/01/2016 22:16:01\t22:25:00\n",
    "2/01/2015 11:17:02\t11:24:50\n",
    "2/01/2015 11:31:38\t11:36:18\n",
    "2/01/2015 11:43:48\t11:50:28\n",
    "2/01/2015 11:51:42\t11:56:38\n",
    "2/01/2015 13:13:02\t13:40:56\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "49de4307-4698-4be9-9da8-7833a57db954",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>name</th>\n",
       "      <th>signal</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SUTD</td>\n",
       "      <td>SWaT</td>\n",
       "      <td>None</td>\n",
       "      <td>2015-12-28 10:29:14</td>\n",
       "      <td>2015-12-28 10:44:53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SUTD</td>\n",
       "      <td>SWaT</td>\n",
       "      <td>None</td>\n",
       "      <td>2015-12-28 10:51:08</td>\n",
       "      <td>2015-12-28 10:58:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SUTD</td>\n",
       "      <td>SWaT</td>\n",
       "      <td>None</td>\n",
       "      <td>2015-12-28 11:22:00</td>\n",
       "      <td>2015-12-28 11:28:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SUTD</td>\n",
       "      <td>SWaT</td>\n",
       "      <td>None</td>\n",
       "      <td>2015-12-28 11:47:39</td>\n",
       "      <td>2015-12-28 11:54:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SUTD</td>\n",
       "      <td>SWaT</td>\n",
       "      <td>None</td>\n",
       "      <td>2015-12-28 12:00:55</td>\n",
       "      <td>2015-12-28 12:04:10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  source  name signal               start                 end\n",
       "0   SUTD  SWaT   None 2015-12-28 10:29:14 2015-12-28 10:44:53\n",
       "1   SUTD  SWaT   None 2015-12-28 10:51:08 2015-12-28 10:58:30\n",
       "2   SUTD  SWaT   None 2015-12-28 11:22:00 2015-12-28 11:28:22\n",
       "3   SUTD  SWaT   None 2015-12-28 11:47:39 2015-12-28 11:54:08\n",
       "4   SUTD  SWaT   None 2015-12-28 12:00:55 2015-12-28 12:04:10"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split = raw_abnormalities.split()\n",
    "abnormalities = {\n",
    "    'start': [],\n",
    "    'end': []\n",
    "}\n",
    "for i in range(0, len(split), 3):\n",
    "    date, start, end = split[i], split[i+1], split[i+2]\n",
    "    abnormalities['start'].append(date + ' ' + start)\n",
    "    abnormalities['end'].append(date + ' ' + end)\n",
    "    \n",
    "abnormalities = pd.DataFrame(abnormalities)\n",
    "\n",
    "abnormalities['source'] = 'SUTD'\n",
    "abnormalities['name'] = 'SWaT'\n",
    "abnormalities['signal'] = None\n",
    "abnormalities['start'] = pd.to_datetime(abnormalities['start'], dayfirst=True)\n",
    "abnormalities['end'] = pd.to_datetime(abnormalities['end'], dayfirst=True)\n",
    "\n",
    "abnormalities = abnormalities[list(abnormalities.columns[-3:]) + list(abnormalities.columns[:-3])]\n",
    "\n",
    "abnormalities.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "44e98346-3732-4d1b-95bd-63efc2066b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = []\n",
    "for idx, abnormality in abnormalities.iterrows():\n",
    "    sub_df = pd.DataFrame(pd.date_range(abnormality['start'], abnormality['end'], freq='1s'))\n",
    "    sub_df['target'] = 1\n",
    "    y.append(sub_df)\n",
    "y = pd.concat(y).set_index(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "116e7088-6152-47cd-96ca-adae25cd9b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = df.iloc[:, 1:52].reset_index()\n",
    "final_df = final_df.rename(columns={' Timestamp': 'index'})\n",
    "\n",
    "final_df['source'] = 'SUTD'\n",
    "final_df['name'] = 'SWaT'\n",
    "final_df['signal'] = None\n",
    "final_df['anomaly'] = df.merge(y, left_index=True, right_index=True, how='left').drop_duplicates()['target'].fillna(0).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "4ef2e9ac-2c69-4fab-8962-02863c713dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = final_df[list(final_df.columns[-4:]) + list(final_df.columns[:-4])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "5bb7c904-a074-4563-b133-0ef9571f809d",
   "metadata": {},
   "outputs": [],
   "source": [
    "split = len(final_df) * 2 // 3\n",
    "train = final_df.iloc[:split]\n",
    "test = final_df.iloc[split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "97f4e711-3d76-4b3e-acfb-613c355abd6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "SWAT_dataset = {\n",
    "    'train': train,\n",
    "    'test': test,\n",
    "    'anomaly': abnormalities\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "66e3b513-15f2-4fc1-9cbe-ad256335b168",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# channels 51\n",
      "# contextual 36\n",
      "# Anomaly 50762\n",
      "# Data 449919\n"
     ]
    }
   ],
   "source": [
    "print_summary(SWAT_dataset['train'], SWAT_dataset['test'], SWAT_dataset['anomaly'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "625d3fad-4984-419b-94ae-4cb541d13a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('processed/datasets/SWaT.pickle', 'wb') as f:\n",
    "    pickle.dump(SWAT_dataset, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "56fad472-10d3-4812-9443-f174624c3f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('processed/datasets/SWaT.pickle', 'rb') as f:\n",
    "    SWAT_dataset_2 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c3f6a62-c7d9-4467-9938-878242b88a39",
   "metadata": {},
   "source": [
    "# WADI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "2d25e648-988c-426b-887e-1f71f576a304",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('datasets/WADI/A1_2017_oct/WADI_attackdataLABLE.csv', header=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "8170a771-0cb5-40e1-a2d7-92f85e2889a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[:-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "d8950f33-606f-47a9-b1ba-4befdf0f97ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "hour = []\n",
    "counter = -1 \n",
    "for t in df.Time:\n",
    "    if t == '00:00.0':\n",
    "        counter += 1\n",
    "    if counter % 24 < 10:\n",
    "        hour.append(f'0{counter % 24}')\n",
    "    else:\n",
    "        hour.append(str(counter % 24))\n",
    "df['hour'] = hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "8667782b-3188-4873-b2ab-d15ead37c82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "datetime = (df['Date '] + ' ' + df['hour']+ ':' + df['Time']).apply(lambda x: str(x)[:-2])\n",
    "df = df.set_index(pd.to_datetime(datetime, dayfirst=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "de6273bc-2ecd-4ef7-88fc-bd0ddf0d3d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_abnormalities = \"\"\"\n",
    "9/10/17 19:25:00 19:50:16\n",
    "10/10/17 10:24:10 10:34:00\n",
    "10/10/17 10:55:00 11:24:00\n",
    "10/10/17 11:30:40 11:44:50\n",
    "10/10/17 13:39:30 13:50:40\n",
    "10/10/17 14:48:17 14:59:55\n",
    "10/10/17 17:40:00 17:49:40\n",
    "11/10/17 10:55:00 10:56:27\n",
    "11/10/17 11:17:54 11:31:20\n",
    "11/10/17 11:36:31 11:47:00\n",
    "11/10/17 11:59:00 12:05:00\n",
    "11/10/17 12:07:30 12:10:52\n",
    "11/10/17 12:16:00 12:25:36\n",
    "11/10/17 15:26:30 15:37:00\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "5d3df716-cb5a-465b-88c5-92e65ec39793",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>name</th>\n",
       "      <th>signal</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SUTD</td>\n",
       "      <td>WADI</td>\n",
       "      <td>None</td>\n",
       "      <td>2017-10-09 19:25:00</td>\n",
       "      <td>2017-10-09 19:50:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SUTD</td>\n",
       "      <td>WADI</td>\n",
       "      <td>None</td>\n",
       "      <td>2017-10-10 10:24:10</td>\n",
       "      <td>2017-10-10 10:34:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SUTD</td>\n",
       "      <td>WADI</td>\n",
       "      <td>None</td>\n",
       "      <td>2017-10-10 10:55:00</td>\n",
       "      <td>2017-10-10 11:24:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SUTD</td>\n",
       "      <td>WADI</td>\n",
       "      <td>None</td>\n",
       "      <td>2017-10-10 11:30:40</td>\n",
       "      <td>2017-10-10 11:44:50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SUTD</td>\n",
       "      <td>WADI</td>\n",
       "      <td>None</td>\n",
       "      <td>2017-10-10 13:39:30</td>\n",
       "      <td>2017-10-10 13:50:40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  source  name signal               start                 end\n",
       "0   SUTD  WADI   None 2017-10-09 19:25:00 2017-10-09 19:50:16\n",
       "1   SUTD  WADI   None 2017-10-10 10:24:10 2017-10-10 10:34:00\n",
       "2   SUTD  WADI   None 2017-10-10 10:55:00 2017-10-10 11:24:00\n",
       "3   SUTD  WADI   None 2017-10-10 11:30:40 2017-10-10 11:44:50\n",
       "4   SUTD  WADI   None 2017-10-10 13:39:30 2017-10-10 13:50:40"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split = raw_abnormalities.split()\n",
    "abnormalities = {\n",
    "    'start': [],\n",
    "    'end': []\n",
    "}\n",
    "for i in range(0, len(split), 3):\n",
    "    date, start, end = split[i], split[i+1], split[i+2]\n",
    "    abnormalities['start'].append(date + ' ' + start)\n",
    "    abnormalities['end'].append(date + ' ' + end)\n",
    "    \n",
    "abnormalities = pd.DataFrame(abnormalities)\n",
    "abnormalities['source'] = 'SUTD'\n",
    "abnormalities['name'] = 'WADI'\n",
    "abnormalities['signal'] = None\n",
    "abnormalities['start'] = pd.to_datetime(abnormalities['start'], dayfirst=True)\n",
    "abnormalities['end'] = pd.to_datetime(abnormalities['end'], dayfirst=True)\n",
    "\n",
    "abnormalities = abnormalities[list(abnormalities.columns[-3:]) + list(abnormalities.columns[:-3])]\n",
    "\n",
    "abnormalities.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "e4fc8da3-458c-4a98-bb55-281c2d346d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = []\n",
    "for idx, abnormality in abnormalities.iterrows():\n",
    "    sub_df = pd.DataFrame(pd.date_range(abnormality['start'], abnormality['end'], freq='1s'))\n",
    "    sub_df['target'] = 1\n",
    "    y.append(sub_df)\n",
    "y = pd.concat(y).set_index(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "409154dd-6443-4058-a317-623b701be76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = df.iloc[:, 3:130].fillna(0).reset_index()\n",
    "final_df = final_df.rename(columns={' Timestamp': 'index'})\n",
    "\n",
    "final_df['source'] = 'SUTD'\n",
    "final_df['name'] = 'WADI'\n",
    "final_df['signal'] = None\n",
    "final_df['anomaly'] = df.merge(y, left_index=True, right_index=True, how='left').drop_duplicates()['target'].fillna(0).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "0a37015d-88a3-4cf9-9438-470a99f7664b",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = final_df[list(final_df.columns[-4:]) + list(final_df.columns[:-4])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "1f314de2-e214-47a5-8b4d-1d3c5e46f8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "split = len(final_df) * 2 // 3\n",
    "train = final_df.iloc[:split]\n",
    "test = final_df.iloc[split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "18b01575-2220-44fd-a7c6-3bd8cb7d23d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "WADI_dataset = {\n",
    "    'train': train,\n",
    "    'test': test,\n",
    "    'anomaly': abnormalities\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "b66fce9f-1757-4eb8-a8cf-ddf23af87b6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# channels 127\n",
      "# contextual 14\n",
      "# Anomaly 5134\n",
      "# Data 172800\n"
     ]
    }
   ],
   "source": [
    "print_summary(WADI_dataset['train'], WADI_dataset['test'], WADI_dataset['anomaly'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "7c1fa518-0154-4e78-be10-d8ee7e568859",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('processed/datasets/WADI.pickle', 'wb') as f:\n",
    "    pickle.dump(WADI_dataset, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814765fc-a1d1-46d4-bae1-94450d1329c8",
   "metadata": {},
   "source": [
    "# Yahoo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "a9921087-678e-4ce0-aa8c-ddbfd29e1fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "A1_dataset = {\n",
    "    'train': [],\n",
    "    'test': [],\n",
    "    'anomaly': [],\n",
    "}\n",
    "\n",
    "for filepath in glob.glob(f'datasets/YAHOO/A1Benchmark/**.csv'):\n",
    "    df = pd.read_csv(filepath)\n",
    "    df['source'] = 'Yahoo'\n",
    "    df['name'] = 'A1'\n",
    "    \n",
    "    filename = os.path.basename(filepath)\n",
    "    signal, _ = filename.split('.')\n",
    "    df['signal'] = signal\n",
    "    df = df[['source', 'name', 'signal', 'is_anomaly', 'timestamp', 'value']]\n",
    "    df = df.rename(columns={'is_anomaly': 'anomaly', 'timestamp': 'index'})\n",
    "\n",
    "    anomaly_index = []\n",
    "    start = None\n",
    "    prev = None\n",
    "    for index, anomaly in zip(df['index'], df.anomaly):\n",
    "        if start is None and anomaly == 1:\n",
    "            start = [index]\n",
    "        elif start is not None and anomaly == 0:\n",
    "            start.append(prev)\n",
    "            anomaly_index.append(start)\n",
    "            start = None\n",
    "        elif start is not None and index == len(df):\n",
    "            start.append(index)\n",
    "            anomaly_index.append(start)\n",
    "        prev = index\n",
    "        \n",
    "\n",
    "    anomaly_index = pd.DataFrame(anomaly_index)\n",
    "    if len(anomaly_index.columns == 2):\n",
    "        anomaly_index.columns = ['start', 'end']\n",
    "        anomaly_index['source'] = 'Yahoo'\n",
    "        anomaly_index['name'] = 'A1'\n",
    "        anomaly_index['signal'] = signal\n",
    "        anomaly_index = anomaly_index[['source', 'name', 'signal', 'start', 'end']]\n",
    "        \n",
    "    split = (len(df) * 2) // 3\n",
    "    train, test = df.iloc[:split], df.iloc[split:]\n",
    "    A1_dataset['train'].append(train)\n",
    "    A1_dataset['test'].append(test)\n",
    "    A1_dataset['anomaly'].append(anomaly_index)\n",
    "\n",
    "A1_dataset['train'] = pd.concat(A1_dataset['train'])\n",
    "A1_dataset['test'] = pd.concat(A1_dataset['test'])\n",
    "A1_dataset['anomaly'] = pd.concat(A1_dataset['anomaly'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "13d147b4-b67d-44c8-9a81-68a29dbad343",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# channels 1\n",
      "# contextual 177\n",
      "# Anomaly 1669\n",
      "# Data 94866\n"
     ]
    }
   ],
   "source": [
    "print_summary(A1_dataset['train'], A1_dataset['test'], A1_dataset['anomaly'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "59ffb146-9641-4fdc-83c9-aab59d063115",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "177 67 110\n"
     ]
    }
   ],
   "source": [
    "b = sum(A1_dataset['anomaly']['start'] == A1_dataset['anomaly']['end'])\n",
    "a = len(A1_dataset['anomaly'])\n",
    "print(a, b, a-b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "96c63cf0-021a-40ed-8c98-abd89ba1a118",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('processed/datasets/A2.pickle', 'wb') as f:\n",
    "    pickle.dump(A1_dataset, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dbed88e-4f08-4169-9732-2cd78f285c41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "27860cda-146c-4e0f-92d2-07a4f92b4014",
   "metadata": {},
   "outputs": [],
   "source": [
    "A3_dataset = {\n",
    "    'train': [],\n",
    "    'test': [],\n",
    "    'anomaly': [],\n",
    "}\n",
    "\n",
    "for filepath in glob.glob(f'datasets/YAHOO/A4Benchmark/A4Benchmark-**.csv'):\n",
    "    df = pd.read_csv(filepath)\n",
    "\n",
    "    df['source'] = 'Yahoo'\n",
    "    df['name'] = 'A4'\n",
    "    \n",
    "    filename = os.path.basename(filepath)\n",
    "    signal, _ = filename.split('.')\n",
    "    df['signal'] = signal\n",
    "    df = df[['source', 'name', 'signal', 'anomaly', 'timestamps', 'value', 'changepoint', 'trend', 'noise',\n",
    "       'seasonality1', 'seasonality2', 'seasonality3']]\n",
    "    df = df.rename(columns={'is_anomaly': 'anomaly', 'timestamps': 'index'})\n",
    "\n",
    "    anomaly_index = []\n",
    "    start = None\n",
    "    prev = None\n",
    "    for index, anomaly in zip(df['index'], df.anomaly):\n",
    "        if start is None and anomaly == 1:\n",
    "            start = [index]\n",
    "        elif start is not None and anomaly == 0:\n",
    "            start.append(prev)\n",
    "            anomaly_index.append(start)\n",
    "            start = None\n",
    "        elif start is not None and index == len(df):\n",
    "            start.append(index)\n",
    "            anomaly_index.append(start)\n",
    "        prev = index\n",
    "        \n",
    "\n",
    "    anomaly_index = pd.DataFrame(anomaly_index)\n",
    "    if len(anomaly_index.columns == 2):\n",
    "        anomaly_index.columns = ['start', 'end']\n",
    "        anomaly_index['source'] = 'Yahoo'\n",
    "        anomaly_index['name'] = 'A4'\n",
    "        anomaly_index['signal'] = signal\n",
    "        anomaly_index = anomaly_index[['source', 'name', 'signal', 'start', 'end']]\n",
    "        \n",
    "    split = (len(df) * 2) // 3\n",
    "    train, test = df.iloc[:split], df.iloc[split:]\n",
    "    A3_dataset['train'].append(train)\n",
    "    A3_dataset['test'].append(test)\n",
    "    A3_dataset['anomaly'].append(anomaly_index)\n",
    "\n",
    "A3_dataset['train'] = pd.concat(A3_dataset['train'])\n",
    "A3_dataset['test'] = pd.concat(A3_dataset['test'])\n",
    "A3_dataset['anomaly'] = pd.concat(A3_dataset['anomaly'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "aaba86d4-c305-4e0b-b712-afd0f6885a3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# channels 7\n",
      "# contextual 834\n",
      "# Anomaly 837\n",
      "# Data 168000\n"
     ]
    }
   ],
   "source": [
    "print_summary(A3_dataset['train'], A3_dataset['test'], A3_dataset['anomaly'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "4e79f0c9-77cb-4a4d-9bb0-36d50f9a3be8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "834 832 2\n"
     ]
    }
   ],
   "source": [
    "b = sum(A3_dataset['anomaly']['start'] == A3_dataset['anomaly']['end'])\n",
    "a = len(A3_dataset['anomaly'])\n",
    "print(a, b, a-b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "59a20557-9ac0-4ac7-bac2-3cd1a582dd77",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('processed/datasets/A4.pickle', 'wb') as f:\n",
    "    pickle.dump(A3_dataset, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e932f907-3391-4eae-bd81-6450eb3d6f17",
   "metadata": {},
   "source": [
    "# NAB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "4f91091e-c879-4af5-b56f-6a9c71d2e7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('datasets/NAB/labels/combined_windows.json', 'rb') as f:\n",
    "    labels = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "d6c54bf0-5d5b-409e-85ec-34b2bcbe524c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = {}\n",
    "for filepath, anomalies in labels.items():\n",
    "    category, filename = filepath.split('/')\n",
    "    if len(anomalies) != 0:\n",
    "        dataset.setdefault(category, dict())\n",
    "        dataset[category].setdefault(filename, [])\n",
    "        dataset[category][filename].extend(anomalies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "id": "671b78a9-360e-4ecd-b344-49edeac15d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Artificial_dataset = {\n",
    "    'train': [],\n",
    "    'test': [],\n",
    "    'anomaly': [],\n",
    "}\n",
    "\n",
    "for filepath in glob.glob(f'datasets/NAB/data/realTweets/**.csv'):\n",
    "    df = pd.read_csv(filepath)\n",
    "    df = df.rename(columns={'timestamp': 'index'})\n",
    "    df['source'] = 'NAB'\n",
    "    df['name'] = 'Tweets'\n",
    "    \n",
    "    filename = os.path.basename(filepath)\n",
    "    signal, _ = filename.split('.')\n",
    "    df['signal'] = signal\n",
    "    \n",
    "    df['anomaly'] = 0\n",
    "    for interval in dataset['realTweets'].get(filename, []):\n",
    "        cond = (interval[0] <= df['index']) & (df['index'] <= interval[1])\n",
    "        df.loc[cond, 'anomaly'] = df.loc[cond, 'anomaly'] + 1\n",
    "    \n",
    "    df = df[['source', 'name', 'signal', 'anomaly', 'index', 'value']]\n",
    "    \n",
    "    \n",
    "    anomaly_index = pd.DataFrame(dataset['realTweets'].get(filename, []))\n",
    "    if len(anomaly_index.columns == 2):\n",
    "        anomaly_index.columns = ['start', 'end']\n",
    "        anomaly_index['source'] = 'NAB'\n",
    "        anomaly_index['name'] = 'Tweets'\n",
    "        anomaly_index['signal'] = signal\n",
    "        anomaly_index = anomaly_index[['source', 'name', 'signal', 'start', 'end']]\n",
    "        \n",
    "    \n",
    "    \n",
    "    split = (len(df) * 2) // 3\n",
    "    train, test = df.iloc[:split], df.iloc[split:]\n",
    "    Artificial_dataset['train'].append(train)\n",
    "    Artificial_dataset['test'].append(test)\n",
    "    Artificial_dataset['anomaly'].append(anomaly_index)\n",
    "\n",
    "    \n",
    "Artificial_dataset['train'] = pd.concat(Artificial_dataset['train'])\n",
    "Artificial_dataset['test'] = pd.concat(Artificial_dataset['test'])\n",
    "Artificial_dataset['anomaly'] = pd.concat(Artificial_dataset['anomaly'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "id": "07666773-7718-40d0-b68f-c3b7bfbed7d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# channels 1\n",
      "# contextual 33\n",
      "# Anomaly 15618\n",
      "# Data 158631\n"
     ]
    }
   ],
   "source": [
    "print_summary(Artificial_dataset['train'], Artificial_dataset['test'], Artificial_dataset['anomaly'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "id": "bdfd43e4-f5fa-42c5-9cdf-5140f062724d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33 0 33\n"
     ]
    }
   ],
   "source": [
    "b = sum(Artificial_dataset['anomaly']['start'] == Artificial_dataset['anomaly']['end'])\n",
    "a = len(Artificial_dataset['anomaly'])\n",
    "print(a, b, a-b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "id": "909f182c-a8ac-4e1d-aa49-69d19187b2da",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('processed/datasets/realTweets.pickle', 'wb') as f:\n",
    "    pickle.dump(Artificial_dataset, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f10bc3-2f60-42c7-a6cc-c97202c3da63",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
