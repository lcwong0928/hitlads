{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0430c6c-b48e-495e-b7b5-63c942a9e70f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "sys.path.append(os.path.dirname(os.path.abspath(os.getcwd())))\n",
    "\n",
    "import collections\n",
    "import logging\n",
    "import os\n",
    "import pathlib\n",
    "import re\n",
    "import string\n",
    "import sys\n",
    "import time\n",
    "import math\n",
    "import tempfile\n",
    "from functools import partial\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from orion.data import load_signal\n",
    "from orion import Orion\n",
    "from orion.data import load_anomalies\n",
    "\n",
    "from mlprimitives.custom.timeseries_preprocessing import time_segments_aggregate\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from mlprimitives.custom.timeseries_preprocessing import rolling_window_sequences\n",
    "from orion.primitives.timeseries_preprocessing import slice_array_by_dims\n",
    "from mlprimitives import load_primitive\n",
    "import numpy as np\n",
    "from orion.primitives.tadgan import TadGAN\n",
    "\n",
    "from tensorflow.keras import backend as K\n",
    "from keras.layers.merge import _Merge\n",
    "\n",
    "from src.configuration.constants import PROCESSED_DATA_DIRECTORY\n",
    "import pickle\n",
    "\n",
    "logging.getLogger('tensorflow').setLevel(logging.ERROR)  # suppress warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11a2962f-6d11-4a5a-807d-6a9b9314f502",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(PROCESSED_DATA_DIRECTORY, 'MSL.pickle'), 'rb') as f:\n",
    "    msl_dataset = pickle.load(f)\n",
    "    \n",
    "with open(os.path.join(PROCESSED_DATA_DIRECTORY, 'MSL_test.pickle'), 'rb') as f:\n",
    "    msl_test_dataset = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1dc634a8-4e48-4645-83ae-12b7e4943b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = msl_dataset['X_train']\n",
    "y_train = msl_dataset['y_train']\n",
    "index_train = msl_dataset['index_train']\n",
    "\n",
    "\n",
    "X_test = msl_test_dataset['X_test']\n",
    "y_test = msl_test_dataset['y_test']\n",
    "index_test = msl_test_dataset['index_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79647cdc-d7e6-4fbe-b281-c7de28b1d9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape=X_train[0].shape\n",
    "target_shape=y_train[0].shape\n",
    "latent_dim=20\n",
    "learning_rate=0.0005\n",
    "epochs=70\n",
    "batch_size=64\n",
    "iterations_critic=5\n",
    "latent_shape = (latent_dim, 1)\n",
    "\n",
    "shape = np.asarray(X_train)[0].shape\n",
    "length = shape[0]\n",
    "target_shape = np.asarray(y_train)[0].shape\n",
    "\n",
    "\n",
    "generator_reshape_dim = length // 2\n",
    "generator_reshape_shape = (length // 2, 1)\n",
    "encoder_reshape_shape = latent_shape\n",
    "\n",
    "encoder_input_shape = shape\n",
    "generator_input_shape = latent_shape\n",
    "critic_x_input_shape = target_shape\n",
    "critic_z_input_shape = latent_shape\n",
    "\n",
    "lstm_units = 100\n",
    "dense_units = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f0f2694-89c5-4652-b0e8-786afc23019d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 100, 55)]         0         \n",
      "_________________________________________________________________\n",
      "sequential_1 (Sequential)    (None, 20, 1)             524820    \n",
      "=================================================================\n",
      "Total params: 524,820\n",
      "Trainable params: 524,820\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def build_encoder(input_shape, lstm_units, dense_units, encoder_reshape_shape):\n",
    "    x = tf.keras.Input(shape=input_shape)\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(units=lstm_units, return_sequences=True)))\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    model.add(tf.keras.layers.Dense(units=dense_units))\n",
    "    model.add(tf.keras.layers.Reshape(target_shape=encoder_reshape_shape))\n",
    "    return tf.keras.Model(x, model(x))\n",
    "              \n",
    "encoder = build_encoder(\n",
    "    input_shape=encoder_input_shape,\n",
    "    lstm_units=lstm_units,\n",
    "    dense_units=dense_units,\n",
    "    encoder_reshape_shape=encoder_reshape_shape,\n",
    ")\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a367b65f-57a9-4ba5-8584-076cc8374cc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 20, 1)]           0         \n",
      "_________________________________________________________________\n",
      "sequential_2 (Sequential)    (None, 100, 1)            133787    \n",
      "=================================================================\n",
      "Total params: 133,787\n",
      "Trainable params: 133,787\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def build_generator(input_shape, generator_reshape_dim, generator_reshape_shape):\n",
    "    x = tf.keras.Input(shape=input_shape)\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    model.add(tf.keras.layers.Dense(units=generator_reshape_dim))\n",
    "    model.add(tf.keras.layers.Reshape(target_shape=generator_reshape_shape))\n",
    "    model.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(units=64, return_sequences=True, dropout=0.2, recurrent_dropout=0.2), merge_mode='concat'))\n",
    "    model.add(tf.keras.layers.UpSampling1D(size=2))\n",
    "    model.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(units=64, return_sequences=True, dropout=0.2, recurrent_dropout=0.2), merge_mode='concat'))\n",
    "    model.add(tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(units=1)))\n",
    "    model.add(tf.keras.layers.Activation(activation='tanh'))\n",
    "    return tf.keras.Model(x, model(x))\n",
    "              \n",
    "generator = build_generator(\n",
    "    input_shape=generator_input_shape,\n",
    "    generator_reshape_dim=generator_reshape_dim,\n",
    "    generator_reshape_shape=generator_reshape_shape,\n",
    ")\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8bb07cdc-8981-41ed-82ac-20d8b4def8e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 100, 1)]          0         \n",
      "_________________________________________________________________\n",
      "sequential_3 (Sequential)    (None, 1)                 67393     \n",
      "=================================================================\n",
      "Total params: 67,393\n",
      "Trainable params: 67,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def build_critic_x(input_shape):\n",
    "    x = tf.keras.Input(shape=input_shape)\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.Conv1D(filters=64, kernel_size=5))\n",
    "    model.add(tf.keras.layers.LeakyReLU(alpha=0.2))\n",
    "    model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "    model.add(tf.keras.layers.Conv1D(filters=64, kernel_size=5))\n",
    "    model.add(tf.keras.layers.LeakyReLU(alpha=0.2))\n",
    "    model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "    model.add(tf.keras.layers.Conv1D(filters=64, kernel_size=5))\n",
    "    model.add(tf.keras.layers.LeakyReLU(alpha=0.2))\n",
    "    model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "    model.add(tf.keras.layers.Conv1D(filters=64, kernel_size=5))\n",
    "    model.add(tf.keras.layers.LeakyReLU(alpha=0.2))\n",
    "    model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    model.add(tf.keras.layers.Dense(units=1))\n",
    "    return tf.keras.Model(x, model(x))\n",
    "              \n",
    "critic_x = build_critic_x(\n",
    "    input_shape=critic_x_input_shape\n",
    ")\n",
    "critic_x.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "72d42253-4eed-45f1-b69f-9496f429dcb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         [(None, 20, 1)]           0         \n",
      "_________________________________________________________________\n",
      "sequential_4 (Sequential)    (None, 1)                 861       \n",
      "=================================================================\n",
      "Total params: 861\n",
      "Trainable params: 861\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def build_critic_z(input_shape, dense_units=20):\n",
    "    x = tf.keras.Input(shape=input_shape)\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    model.add(tf.keras.layers.Dense(units=dense_units))\n",
    "    model.add(tf.keras.layers.LeakyReLU(alpha=0.2))\n",
    "    model.add(tf.keras.layers.Dropout(rate=0.2))\n",
    "    model.add(tf.keras.layers.Dense(units=dense_units))\n",
    "    model.add(tf.keras.layers.LeakyReLU(alpha=0.2))\n",
    "    model.add(tf.keras.layers.Dropout(rate=0.2))\n",
    "    model.add(tf.keras.layers.Dense(units=1))\n",
    "    return tf.keras.Model(x, model(x))\n",
    "              \n",
    "critic_z = build_critic_z(\n",
    "    input_shape=critic_z_input_shape,\n",
    ")\n",
    "critic_z.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "59895bba-c11b-4001-88f0-3b0908a8946c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomWeightedAverage(_Merge):\n",
    "    def _merge_function(self, inputs):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            inputs[0] x     original input\n",
    "            inputs[1] x_    predicted input\n",
    "        \"\"\"\n",
    "        alpha = K.random_uniform((64, 1, 1))\n",
    "        return (alpha * inputs[0]) + ((1 - alpha) * inputs[1])\n",
    "\n",
    "def _wasserstein_loss(y_true, y_pred):\n",
    "    return K.mean(y_true * y_pred)\n",
    "\n",
    "def _gradient_penalty_loss(y_true, y_pred, averaged_samples):\n",
    "    gradients = K.gradients(y_pred, averaged_samples)[0]\n",
    "    gradients_sqr = K.square(gradients)\n",
    "    gradients_sqr_sum = K.sum(gradients_sqr, axis=np.arange(1, len(gradients_sqr.shape)))\n",
    "    gradient_l2_norm = K.sqrt(gradients_sqr_sum)\n",
    "    gradient_penalty = K.square(1 - gradient_l2_norm)\n",
    "    return K.mean(gradient_penalty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "41a8e774-7ad3-4c0f-9672-d318aba04578",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f92da33b-83e2-4d84-a491-fffab2f19fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator.trainable = False\n",
    "encoder.trainable = False\n",
    "\n",
    "x = tf.keras.Input(shape=input_shape)\n",
    "y = tf.keras.Input(shape=target_shape)\n",
    "z = tf.keras.Input(shape=(latent_dim, 1))\n",
    "\n",
    "x_ = generator(z)\n",
    "z_ = encoder(x)\n",
    "fake_x = critic_x(x_) # Fake\n",
    "valid_x = critic_x(y) # Truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4819b71b-fda8-4b44-ad31-8b21c8609045",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-22 02:26:03.937209: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2022-01-22 02:26:03.973510: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f98e075c510 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2022-01-22 02:26:03.973529: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n"
     ]
    }
   ],
   "source": [
    "# interpolated_x = RandomWeightedAverage()([y, x_])\n",
    "alpha = K.random_uniform((64, 1, 1))\n",
    "interpolated_x = (alpha * [y, x_][0]) + ((1 - alpha) * [y, x_][1])\n",
    "validity_interpolated_x = critic_x(interpolated_x)\n",
    "partial_gp_loss_x = partial(_gradient_penalty_loss, averaged_samples=interpolated_x)\n",
    "partial_gp_loss_x.__name__ = 'gradient_penalty'\n",
    "critic_x_model = tf.keras.Model(inputs=[y, z], outputs=[valid_x, fake_x, validity_interpolated_x])\n",
    "critic_x_model.compile(loss=[_wasserstein_loss, _wasserstein_loss, partial_gp_loss_x, 'sparse_categorical_crossentropy'], \n",
    "                       optimizer=optimizer, loss_weights=[1, 1, 10, 1])\n",
    "\n",
    "\n",
    "    d_out_layer = Dense(1, activation='sigmoid')(fe)\n",
    "    d_model = Model(in_image, d_out_layer)\n",
    "    d_model.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.0002, beta_1=0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6e3e41-b94d-4667-b5ac-da0bb9d1db94",
   "metadata": {},
   "outputs": [],
   "source": [
    "    c_out_layer = Dense(2, activation='softmax')(fe)\n",
    "    c_model = Model(in_image, c_out_layer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
