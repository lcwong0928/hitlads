{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ae112aa-175e-4af5-9a19-74aebac7aac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.append(os.path.dirname(os.path.abspath(os.getcwd())))\n",
    "\n",
    "from src.configuration.constants import PROCESSED_DATA_DIRECTORY, ROOT_DIRECTORY, INTERIM_DATA_DIRECTORY, LOGS_DATA_DIRECTORY\n",
    "from src.utils.dataset import load_dataset\n",
    "\n",
    "\n",
    "import collections\n",
    "import logging\n",
    "import os\n",
    "import pathlib\n",
    "import re\n",
    "import string\n",
    "import sys\n",
    "import time\n",
    "import math\n",
    "import tempfile\n",
    "from functools import partial\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from orion.data import load_signal\n",
    "from orion import Orion\n",
    "from orion.data import load_anomalies\n",
    "\n",
    "import tensorflow as tf\n",
    "from functools import partial\n",
    "from mlprimitives import load_primitive\n",
    "\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras import backend as K\n",
    "from orion.evaluation.contextual import contextual_f1_score\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "\n",
    "from mlprimitives import load_primitive\n",
    "\n",
    "logging.getLogger('tensorflow').setLevel(logging.ERROR)  # suppress warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05293c8e-2839-4598-821d-474857b6cabf",
   "metadata": {},
   "source": [
    "# Positional encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b93e416-9b47-4fa6-a5d1-a488a858b7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_angles(pos, i, d_model):\n",
    "    angle_rates = 1 / np.power(10000, (2 * (i//2)) / np.float32(d_model))\n",
    "    return pos * angle_rates\n",
    "\n",
    "def positional_encoding(position, d_model):\n",
    "    angle_rads = get_angles(np.arange(position)[:, np.newaxis],\n",
    "                          np.arange(d_model)[np.newaxis, :],\n",
    "                          d_model)\n",
    "\n",
    "    # apply sin to even indices in the array; 2i\n",
    "    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
    "\n",
    "    # apply cos to odd indices in the array; 2i+1\n",
    "    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
    "\n",
    "    pos_encoding = angle_rads[np.newaxis, ...]\n",
    "\n",
    "    return tf.cast(pos_encoding, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5d3b2020-d0f2-4ce0-8133-9d524f936295",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 100, 25)\n"
     ]
    }
   ],
   "source": [
    "# Test Example\n",
    "n, d = 100, 25\n",
    "pos_encoding = positional_encoding(n, d)\n",
    "print(pos_encoding.shape)\n",
    "pos_encoding = pos_encoding[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e0b0eb-46f3-4159-9811-ee0333650a97",
   "metadata": {},
   "source": [
    "# Masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1908e393-966f-4226-83fe-4088a630dd8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_padding_mask(seq):\n",
    "    seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
    "\n",
    "    # add extra dimensions to add the padding\n",
    "    # to the attention logits.\n",
    "    return seq[:, tf.newaxis, tf.newaxis, :]  # (batch_size, 1, 1, seq_len)\n",
    "\n",
    "def create_look_ahead_mask(size):\n",
    "    mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
    "    return mask  # (seq_len, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "12db03fc-440a-410f-be3e-36c5fd2b44c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'strided_slice_3:0' shape=(3, 1, 1, 5) dtype=float32>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 0 are pads\n",
    "x = tf.constant([[7, 6, 0, 0, 1], [1, 2, 3, 0, 0], [0, 0, 0, 4, 5]])\n",
    "create_padding_mask(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "87a9daaa-c2e1-462d-8989-fe838d53c5f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'sub_1:0' shape=(3, 3) dtype=float32>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look-ahead mask\n",
    "x = tf.random.uniform((1, 3))\n",
    "temp = create_look_ahead_mask(x.shape[1])\n",
    "temp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a085f38-a11e-41d0-a0d2-708347dc411f",
   "metadata": {},
   "source": [
    "# Multihead Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cb305436-3f9b-42b5-8e46-e9153544bd06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([Dimension(1), Dimension(100), Dimension(25)]),\n",
       " TensorShape([Dimension(1), Dimension(5), Dimension(100), Dimension(100)]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.models.layers import MultiHeadAttention\n",
    "\n",
    "temp_mha = MultiHeadAttention(d_model=25, num_heads=5)\n",
    "y = tf.random.uniform((1, 100, 25))  # (batch_size, encoder_sequence, d_model)\n",
    "out, attn = temp_mha(y, k=y, q=y, mask=None)\n",
    "out.shape, attn.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7904c053-5e6e-46ce-bc23-b4dba7fb400e",
   "metadata": {},
   "source": [
    "# Point wise feed forward network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bc8e4477-b6da-4d01-8d05-188e9aebfc7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(64), Dimension(50), Dimension(512)])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.models.layers import point_wise_feed_forward_network\n",
    "\n",
    "sample_ffn = point_wise_feed_forward_network(512, 2048)\n",
    "sample_ffn(tf.random.uniform((64, 50, 512))).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e10ecd-397e-43bb-8d8b-fcf162301da0",
   "metadata": {},
   "source": [
    "# Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "60cbc86f-0d71-423b-a79c-1e4c18a7512e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(64), Dimension(43), Dimension(512)])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.models.layers import EncoderLayer\n",
    "\n",
    "sample_encoder_layer = EncoderLayer(512, 8, 2048)\n",
    "\n",
    "sample_encoder_layer_output = sample_encoder_layer(\n",
    "    tf.random.uniform((64, 43, 512)), False, None)\n",
    "\n",
    "sample_encoder_layer_output.shape  # (batch_size, input_seq_len, d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8425c956-a251-4698-8bec-6e30dd9cb3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.layers.Layer):\n",
    "  def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size,\n",
    "               maximum_position_encoding, rate=0.1):\n",
    "    super(Encoder, self).__init__()\n",
    "\n",
    "    self.d_model = d_model\n",
    "    self.num_layers = num_layers\n",
    "\n",
    "    # self.embedding = tf.keras.layers.Embedding(input_vocab_size, d_model)\n",
    "    self.pos_encoding = positional_encoding(maximum_position_encoding,\n",
    "                                            self.d_model)\n",
    "\n",
    "    self.enc_layers = [EncoderLayer(d_model, num_heads, dff, rate)\n",
    "                       for _ in range(num_layers)]\n",
    "\n",
    "    self.dropout = tf.keras.layers.Dropout(rate)\n",
    "\n",
    "  def call(self, x, training, mask):\n",
    "\n",
    "    seq_len = tf.shape(x)[1]\n",
    "\n",
    "    # adding embedding and position encoding.\n",
    "    # x = self.embedding(x)  # (batch_size, input_seq_len, d_model)\n",
    "    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "    x += self.pos_encoding[:, :seq_len, :]\n",
    "   \n",
    "\n",
    "    x = self.dropout(x, training=training)\n",
    "\n",
    "    for i in range(self.num_layers):\n",
    "      x = self.enc_layers[i](x, training, mask)\n",
    "\n",
    "    return x  # (batch_size, input_seq_len, d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a4de6f8c-0410-4eb5-ac11-f7971bf73c5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 100, 25)\n"
     ]
    }
   ],
   "source": [
    "sample_encoder = Encoder(num_layers=2, d_model=25, num_heads=5,\n",
    "                         dff=1, input_vocab_size=None,\n",
    "                         maximum_position_encoding=10000)\n",
    "temp_input = tf.random.uniform((1, 100, 25), dtype=tf.float32, minval=0, maxval=200)\n",
    "\n",
    "sample_encoder_output = sample_encoder(temp_input, training=False, mask=None)\n",
    "\n",
    "print(sample_encoder_output.shape)  # (batch_size, input_seq_len, d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "00004a60-9258-4150-be69-7999f906b651",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_encoder.trainable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82983a06-dfde-4907-a376-edb7b2cf88b1",
   "metadata": {},
   "source": [
    "# Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c473c4fb-fb1c-4ca9-b0f8-5f4c94ce8d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(tf.keras.layers.Layer):\n",
    "  def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
    "    super(DecoderLayer, self).__init__()\n",
    "\n",
    "    self.mha1 = MultiHeadAttention(d_model, num_heads)\n",
    "    self.mha2 = MultiHeadAttention(d_model, num_heads)\n",
    "\n",
    "    self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
    "\n",
    "    self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "    self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "    self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "    self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "    self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "    self.dropout3 = tf.keras.layers.Dropout(rate)\n",
    "\n",
    "  def call(self, x, enc_output, training,\n",
    "           look_ahead_mask, padding_mask):\n",
    "    # enc_output.shape == (batch_size, input_seq_len, d_model)\n",
    "\n",
    "    attn1, attn_weights_block1 = self.mha1(x, x, x, look_ahead_mask)  # (batch_size, target_seq_len, d_model)\n",
    "    attn1 = self.dropout1(attn1, training=training)\n",
    "    out1 = self.layernorm1(attn1 + x)\n",
    "\n",
    "    attn2, attn_weights_block2 = self.mha2(\n",
    "        enc_output, enc_output, out1, padding_mask)  # (batch_size, target_seq_len, d_model)\n",
    "    attn2 = self.dropout2(attn2, training=training)\n",
    "    out2 = self.layernorm2(attn2 + out1)  # (batch_size, target_seq_len, d_model)\n",
    "\n",
    "    ffn_output = self.ffn(out2)  # (batch_size, target_seq_len, d_model)\n",
    "    ffn_output = self.dropout3(ffn_output, training=training)\n",
    "    out3 = self.layernorm3(ffn_output + out2)  # (batch_size, target_seq_len, d_model)\n",
    "\n",
    "    return out3, attn_weights_block1, attn_weights_block2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b613520c-ff78-40fb-9e07-2191b29b45e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(64), Dimension(50), Dimension(512)])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_decoder_layer = DecoderLayer(512, 8, 2048)\n",
    "\n",
    "sample_decoder_layer_output, _, _ = sample_decoder_layer(\n",
    "    tf.random.uniform((64, 50, 512)), sample_encoder_layer_output,\n",
    "    False, None, None)\n",
    "\n",
    "sample_decoder_layer_output.shape  # (batch_size, target_seq_len, d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cc85bb54-508f-47a1-a76d-37f9fcfcd1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.layers.Layer):\n",
    "  def __init__(self, num_layers, d_model, num_heads, dff, target_vocab_size,\n",
    "               maximum_position_encoding, rate=0.1):\n",
    "    super(Decoder, self).__init__()\n",
    "\n",
    "    self.d_model = d_model\n",
    "    self.num_layers = num_layers\n",
    "\n",
    "    self.embedding = tf.keras.layers.Embedding(target_vocab_size, d_model)\n",
    "    self.pos_encoding = positional_encoding(maximum_position_encoding, d_model)\n",
    "\n",
    "    self.dec_layers = [DecoderLayer(d_model, num_heads, dff, rate)\n",
    "                       for _ in range(num_layers)]\n",
    "    self.dropout = tf.keras.layers.Dropout(rate)\n",
    "\n",
    "  def call(self, x, enc_output, training,\n",
    "           look_ahead_mask, padding_mask):\n",
    "\n",
    "    seq_len = tf.shape(x)[1]\n",
    "    attention_weights = {}\n",
    "\n",
    "    x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
    "    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "    x += self.pos_encoding[:, :seq_len, :]\n",
    "\n",
    "    x = self.dropout(x, training=training)\n",
    "\n",
    "    for i in range(self.num_layers):\n",
    "      x, block1, block2 = self.dec_layers[i](x, enc_output, training,\n",
    "                                             look_ahead_mask, padding_mask)\n",
    "\n",
    "      attention_weights[f'decoder_layer{i+1}_block1'] = block1\n",
    "      attention_weights[f'decoder_layer{i+1}_block2'] = block2\n",
    "\n",
    "    # x.shape == (batch_size, target_seq_len, d_model)\n",
    "    return x, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b06b7fbe-a7f0-4de4-b64f-7e72e21eaad4",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in converted code:\n\n    /var/folders/_5/f7yzqnxs6694l3c_yk9mjpzr0000gn/T/ipykernel_85722/955386546.py:29 call  *\n        x, block1, block2 = self.dec_layers[i](x, enc_output, training,\n    /Users/lcwong/opt/anaconda3/envs/hitlads-env/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py:854 __call__\n        outputs = call_fn(cast_inputs, *args, **kwargs)\n    /var/folders/_5/f7yzqnxs6694l3c_yk9mjpzr0000gn/T/ipykernel_85722/1969818830.py:26 call  *\n        attn2, attn_weights_block2 = self.mha2(\n    /Users/lcwong/opt/anaconda3/envs/hitlads-env/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py:854 __call__\n        outputs = call_fn(cast_inputs, *args, **kwargs)\n    /Users/lcwong/PycharmProjects/hitlads/src/models/layers/transformer.py:103 call  *\n        k = self.split_heads(k, batch_size)  # (batch_size, num_heads, seq_len_k, depth)\n    /Users/lcwong/PycharmProjects/hitlads/src/models/layers/transformer.py:92 split_heads  *\n        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n    /Users/lcwong/opt/anaconda3/envs/hitlads-env/lib/python3.7/site-packages/tensorflow_core/python/ops/array_ops.py:131 reshape\n        result = gen_array_ops.reshape(tensor, shape, name)\n    /Users/lcwong/opt/anaconda3/envs/hitlads-env/lib/python3.7/site-packages/tensorflow_core/python/ops/gen_array_ops.py:8115 reshape\n        \"Reshape\", tensor=tensor, shape=shape, name=name)\n    /Users/lcwong/opt/anaconda3/envs/hitlads-env/lib/python3.7/site-packages/tensorflow_core/python/framework/op_def_library.py:794 _apply_op_helper\n        op_def=op_def)\n    /Users/lcwong/opt/anaconda3/envs/hitlads-env/lib/python3.7/site-packages/tensorflow_core/python/util/deprecation.py:507 new_func\n        return func(*args, **kwargs)\n    /Users/lcwong/opt/anaconda3/envs/hitlads-env/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py:3357 create_op\n        attrs, op_def, compute_device)\n    /Users/lcwong/opt/anaconda3/envs/hitlads-env/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py:3426 _create_op_internal\n        op_def=op_def)\n    /Users/lcwong/opt/anaconda3/envs/hitlads-env/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py:1770 __init__\n        control_input_ops)\n    /Users/lcwong/opt/anaconda3/envs/hitlads-env/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py:1610 _create_c_op\n        raise ValueError(str(e))\n\n    ValueError: Dimension size must be evenly divisible by 32768 but is 51200 for 'decoder/decoder_layer_1/multi_head_attention_7/Reshape_1' (op: 'Reshape') with input shapes: [1,100,512], [4] and with input tensors computed as partial shapes: input[1] = [64,?,8,64].\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/_5/f7yzqnxs6694l3c_yk9mjpzr0000gn/T/ipykernel_85722/3239313571.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m                               \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m                               \u001b[0mlook_ahead_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m                               padding_mask=None)\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'decoder_layer2_block2'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/hitlads-env/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    852\u001b[0m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_layer_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmark_as_return\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 854\u001b[0;31m                   \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    855\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    856\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOperatorNotAllowedInGraphError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/hitlads-env/lib/python3.7/site-packages/tensorflow_core/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    235\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m           \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m           \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in converted code:\n\n    /var/folders/_5/f7yzqnxs6694l3c_yk9mjpzr0000gn/T/ipykernel_85722/955386546.py:29 call  *\n        x, block1, block2 = self.dec_layers[i](x, enc_output, training,\n    /Users/lcwong/opt/anaconda3/envs/hitlads-env/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py:854 __call__\n        outputs = call_fn(cast_inputs, *args, **kwargs)\n    /var/folders/_5/f7yzqnxs6694l3c_yk9mjpzr0000gn/T/ipykernel_85722/1969818830.py:26 call  *\n        attn2, attn_weights_block2 = self.mha2(\n    /Users/lcwong/opt/anaconda3/envs/hitlads-env/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py:854 __call__\n        outputs = call_fn(cast_inputs, *args, **kwargs)\n    /Users/lcwong/PycharmProjects/hitlads/src/models/layers/transformer.py:103 call  *\n        k = self.split_heads(k, batch_size)  # (batch_size, num_heads, seq_len_k, depth)\n    /Users/lcwong/PycharmProjects/hitlads/src/models/layers/transformer.py:92 split_heads  *\n        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n    /Users/lcwong/opt/anaconda3/envs/hitlads-env/lib/python3.7/site-packages/tensorflow_core/python/ops/array_ops.py:131 reshape\n        result = gen_array_ops.reshape(tensor, shape, name)\n    /Users/lcwong/opt/anaconda3/envs/hitlads-env/lib/python3.7/site-packages/tensorflow_core/python/ops/gen_array_ops.py:8115 reshape\n        \"Reshape\", tensor=tensor, shape=shape, name=name)\n    /Users/lcwong/opt/anaconda3/envs/hitlads-env/lib/python3.7/site-packages/tensorflow_core/python/framework/op_def_library.py:794 _apply_op_helper\n        op_def=op_def)\n    /Users/lcwong/opt/anaconda3/envs/hitlads-env/lib/python3.7/site-packages/tensorflow_core/python/util/deprecation.py:507 new_func\n        return func(*args, **kwargs)\n    /Users/lcwong/opt/anaconda3/envs/hitlads-env/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py:3357 create_op\n        attrs, op_def, compute_device)\n    /Users/lcwong/opt/anaconda3/envs/hitlads-env/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py:3426 _create_op_internal\n        op_def=op_def)\n    /Users/lcwong/opt/anaconda3/envs/hitlads-env/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py:1770 __init__\n        control_input_ops)\n    /Users/lcwong/opt/anaconda3/envs/hitlads-env/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py:1610 _create_c_op\n        raise ValueError(str(e))\n\n    ValueError: Dimension size must be evenly divisible by 32768 but is 51200 for 'decoder/decoder_layer_1/multi_head_attention_7/Reshape_1' (op: 'Reshape') with input shapes: [1,100,512], [4] and with input tensors computed as partial shapes: input[1] = [64,?,8,64].\n"
     ]
    }
   ],
   "source": [
    "sample_decoder = Decoder(num_layers=2, d_model=512, num_heads=8,\n",
    "                         dff=2048, target_vocab_size=8000,\n",
    "                         maximum_position_encoding=5000)\n",
    "temp_input = tf.random.uniform((64, 26), dtype=tf.float32, minval=0, maxval=200)\n",
    "\n",
    "output, attn = sample_decoder(temp_input,\n",
    "                              enc_output=sample_encoder_output,\n",
    "                              training=False,\n",
    "                              look_ahead_mask=None,\n",
    "                              padding_mask=None)\n",
    "\n",
    "output.shape, attn['decoder_layer2_block2'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2180e4ff-1377-4360-bcd0-71e43a27f516",
   "metadata": {},
   "source": [
    "# Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64faf67-e037-45bf-8a5e-cdfb28ccb5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(tf.keras.Model):\n",
    "  def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size,\n",
    "               target_vocab_size, pe_input, pe_target, rate=0.1):\n",
    "    super().__init__()\n",
    "    self.encoder = Encoder(num_layers, d_model, num_heads, dff,\n",
    "                             input_vocab_size, pe_input, rate)\n",
    "\n",
    "    self.decoder = Decoder(num_layers, d_model, num_heads, dff,\n",
    "                           target_vocab_size, pe_target, rate)\n",
    "\n",
    "    self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n",
    "\n",
    "  def call(self, inputs, training):\n",
    "    # Keras models prefer if you pass all your inputs in the first argument\n",
    "    inp, tar = inputs\n",
    "\n",
    "    enc_padding_mask, look_ahead_mask, dec_padding_mask = self.create_masks(inp, tar)\n",
    "\n",
    "    enc_output = self.encoder(inp, training, enc_padding_mask)  # (batch_size, inp_seq_len, d_model)\n",
    "\n",
    "    # dec_output.shape == (batch_size, tar_seq_len, d_model)\n",
    "    dec_output, attention_weights = self.decoder(\n",
    "        tar, enc_output, training, look_ahead_mask, dec_padding_mask)\n",
    "\n",
    "    final_output = self.final_layer(dec_output)  # (batch_size, tar_seq_len, target_vocab_size)\n",
    "\n",
    "    return final_output, attention_weights\n",
    "\n",
    "  def create_masks(self, inp, tar):\n",
    "    # Encoder padding mask\n",
    "    enc_padding_mask = create_padding_mask(inp)\n",
    "\n",
    "    # Used in the 2nd attention block in the decoder.\n",
    "    # This padding mask is used to mask the encoder outputs.\n",
    "    dec_padding_mask = create_padding_mask(inp)\n",
    "\n",
    "    # Used in the 1st attention block in the decoder.\n",
    "    # It is used to pad and mask future tokens in the input received by\n",
    "    # the decoder.\n",
    "    look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])\n",
    "    dec_target_padding_mask = create_padding_mask(tar)\n",
    "    look_ahead_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n",
    "\n",
    "    return enc_padding_mask, look_ahead_mask, dec_padding_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42fc01d0-9ddd-4405-89e1-6a4a6952fa48",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_transformer = Transformer(\n",
    "    num_layers=2, d_model=512, num_heads=8, dff=2048,\n",
    "    input_vocab_size=8500, target_vocab_size=8000,\n",
    "    pe_input=10000, pe_target=6000)\n",
    "\n",
    "temp_input = tf.random.uniform((64, 38), dtype=tf.float32, minval=0, maxval=200)\n",
    "temp_target = tf.random.uniform((64, 36), dtype=tf.float32, minval=0, maxval=200)\n",
    "\n",
    "fn_out, _ = sample_transformer([temp_input, temp_target], training=False)\n",
    "\n",
    "fn_out.shape  # (batch_size, tar_seq_len, target_vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e06e4164-c620-4e3b-96e4-3589c863f28e",
   "metadata": {},
   "source": [
    "# Attention TadGAN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0127c80-e492-499d-af9b-661365ea53fb",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf3f8e7b-0b05-42fa-aa15-d622d56b4402",
   "metadata": {},
   "source": [
    "### Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "716a611d-50b9-4def-ad59-784355637c08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['M-1', 'M-2', 'M-3', 'M-7', 'T-5', 'T-4', 'M-6', 'M-4', 'M-5', 'F-8', 'S-2', 'D-15', 'P-14', 'P-15', 'D-14', 'D-16', 'F-7', 'P-11', 'F-5', 'F-4', 'P-10', 'T-13', 'T-12', 'T-9', 'T-8', 'C-1', 'C-2'])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset('interim', 'MSL')\n",
    "\n",
    "train_split = dataset['train']\n",
    "test_split = dataset['test']\n",
    "anomalies_split = dataset['anomaly']\n",
    "\n",
    "signal_to_dataset = {}\n",
    "for signal in train_split.signal.unique():\n",
    "    signal_to_dataset[signal] = {\n",
    "        'train': train_split[train_split.signal == signal],\n",
    "        'test': test_split[test_split.signal == signal],\n",
    "        'anomaly': anomalies_split[anomalies_split.signal == signal],\n",
    "    }\n",
    "\n",
    "signal_to_dataset.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6ce0c4f8-0555-4930-853e-10f8af7e52d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "m2_dataset = signal_to_dataset['M-2']\n",
    "\n",
    "train = m2_dataset['train']\n",
    "test = m2_dataset['test']\n",
    "anomalies = m2_dataset['anomaly']\n",
    "\n",
    "index_train = train['index'].astype(int)\n",
    "X_train = train[['anomaly'] + list(train.columns)[5:]]\n",
    "\n",
    "index_test = test['index'].astype(int).reset_index(drop=True)\n",
    "X_test = test[['anomaly'] + list(test.columns)[5:]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba27796-9d35-4c95-93ea-faad35144de6",
   "metadata": {},
   "source": [
    "### Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "20a0a108-608a-4ab9-80ba-6ed1717967a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_processing(X, index):\n",
    "    primitives = []\n",
    "    \n",
    "    \n",
    "    # This primitive is an imputation transformer for filling missing values\n",
    "    params = {\n",
    "        'X': X\n",
    "    }\n",
    "    primitive = load_primitive('sklearn.impute.SimpleImputer', arguments=params)\n",
    "    primitive.fit()\n",
    "    primitives.append(primitive)\n",
    "    X = primitive.produce(X=X)\n",
    "    print(primitive, X.shape)\n",
    "    \n",
    "    # This primitive transforms features by scaling each feature to a given range\n",
    "    params = {\n",
    "        \"feature_range\": [-1, 1], \n",
    "        'X': X,\n",
    "    }\n",
    "    primitive = load_primitive('sklearn.preprocessing.MinMaxScaler', arguments=params)\n",
    "    primitive.fit()\n",
    "    primitives.append(primitive)\n",
    "    X = primitive.produce(X=X)\n",
    "    print(primitive, X.shape)\n",
    "    \n",
    "    # Uses a rolling window approach to create the sub-sequences out of time series data\n",
    "    params = {\n",
    "        \"target_column\": 0, \n",
    "        \"window_size\": 100, \n",
    "        'target_size': 1, \n",
    "        'step_size': 1\n",
    "    }\n",
    "    primitive = load_primitive('mlprimitives.custom.timeseries_preprocessing.rolling_window_sequences',\n",
    "                               arguments=params)\n",
    "    primitives.append(primitive)\n",
    "    X, y, index, target_index = primitive.produce(X=X, index=index)\n",
    "\n",
    "    # Target / target size is the next interval that is trying to predict.\n",
    "    # Index is the start of the interval\n",
    "    print(primitive, X.shape, y.shape, index.shape, target_index.shape)\n",
    "    \n",
    "    return X, index, primitives "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4bc5b782-d4b3-422d-ab0c-da8e17a32011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLBlock - sklearn.impute.SimpleImputer (2208, 56)\n",
      "MLBlock - sklearn.preprocessing.MinMaxScaler (2208, 56)\n",
      "MLBlock - mlprimitives.custom.timeseries_preprocessing.rolling_window_sequences (2108, 100, 56) (2108, 1) (2108,) (2108,)\n"
     ]
    }
   ],
   "source": [
    "X, index, primitives = fit_processing(X_train, index_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6289f6aa-16ca-4c49-a316-eea5a54a0034",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2108, 100, 55), (2108, 100, 1), (2108,))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X[:, :, 1:]\n",
    "y_train = np.expand_dims(X_train[:, :, 0], 2)\n",
    "index_train = index\n",
    "\n",
    "X_train.shape, y_train.shape, index_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1ce18484-e2a7-42bd-be1b-845b119ec0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def produce_processing(X, index, primitives):\n",
    "    X = primitives[0].produce(X=X)\n",
    "    X = primitives[1].produce(X=X)\n",
    "    X, y, index, target_index = primitives[2].produce(X=X, index=index)\n",
    "    return X, index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3391f60a-5bc5-47e4-8ac0-4077f1a39cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, index = produce_processing(X_test, index_test, primitives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7755f2cf-d934-4f40-9495-738de869c33d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2177, 100, 55), (2177, 100, 1), (2177,), (2177,))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = X[:, :, 1:]\n",
    "y_test = np.expand_dims(X_test[:, :, 0], 2)\n",
    "index_test = index\n",
    "labels_test = np.array([1 if sum(i) > 0 else 0 for i in X[:, :, 0]])\n",
    "\n",
    "\n",
    "X_test.shape, y_test.shape, index_test.shape, labels_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f0faff-ffac-498d-933d-cdca0609afcb",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b782d889-0ad4-4a37-9a83-349feac64788",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape=X_train[0].shape\n",
    "target_shape=y_train[0].shape\n",
    "latent_dim=20\n",
    "learning_rate=0.0005\n",
    "epochs=70\n",
    "batch_size=64\n",
    "iterations_critic=5\n",
    "latent_shape = (latent_dim, 1)\n",
    "\n",
    "shape = np.asarray(X_train)[0].shape\n",
    "length = shape[0]\n",
    "target_shape = np.asarray(y_train)[0].shape\n",
    "\n",
    "\n",
    "generator_reshape_dim = length // 2\n",
    "generator_reshape_shape = (length // 2, 1)\n",
    "encoder_reshape_shape = latent_shape\n",
    "\n",
    "encoder_input_shape = shape\n",
    "generator_input_shape = latent_shape\n",
    "critic_x_input_shape = target_shape\n",
    "critic_z_input_shape = latent_shape\n",
    "\n",
    "lstm_units = 100\n",
    "dense_units = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "3b29a316-3e9d-4954-a48d-9024d38435c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_20 (InputLayer)        [(None, 100, 55)]         0         \n",
      "_________________________________________________________________\n",
      "sequential_20 (Sequential)   (None, 20, 1)             135432    \n",
      "=================================================================\n",
      "Total params: 135,432\n",
      "Trainable params: 135,432\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def build_encoder(input_shape, lstm_units, dense_units, encoder_reshape_shape):\n",
    "    x = tf.keras.Input(shape=input_shape)\n",
    "    model = tf.keras.models.Sequential()\n",
    "    # model.add(keras.layers.Bidirectional(keras.layers.LSTM(units=lstm_units, return_sequences=True)))\n",
    "    model.add(Encoder(num_layers=2, d_model=input_shape[-1], num_heads=5,\n",
    "                      dff=1, input_vocab_size=None,\n",
    "                      maximum_position_encoding=10000))\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    model.add(tf.keras.layers.Dense(units=dense_units))\n",
    "    model.add(tf.keras.layers.Reshape(target_shape=encoder_reshape_shape))\n",
    "    return tf.keras.Model(x, model(x))\n",
    "              \n",
    "encoder = build_encoder(\n",
    "    input_shape=encoder_input_shape,\n",
    "    lstm_units=lstm_units,\n",
    "    dense_units=dense_units,\n",
    "    encoder_reshape_shape=encoder_reshape_shape,\n",
    ")\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "9ecd1277-7587-4360-a016-94287c60c33b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_21 (InputLayer)        [(None, 20, 1)]           0         \n",
      "_________________________________________________________________\n",
      "sequential_23 (Sequential)   (None, 100, 1)            133787    \n",
      "=================================================================\n",
      "Total params: 133,787\n",
      "Trainable params: 133,787\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def build_generator(input_shape, generator_reshape_dim, generator_reshape_shape):\n",
    "    x = tf.keras.Input(shape=input_shape)\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    model.add(tf.keras.layers.Dense(units=generator_reshape_dim))\n",
    "    model.add(tf.keras.layers.Reshape(target_shape=generator_reshape_shape))\n",
    "    model.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(units=64, return_sequences=True, dropout=0.2, recurrent_dropout=0.2), merge_mode='concat'))\n",
    "    \n",
    "    model.add(tf.keras.layers.UpSampling1D(size=2))\n",
    "    model.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(units=64, return_sequences=True, dropout=0.2, recurrent_dropout=0.2), merge_mode='concat'))\n",
    "    model.add(tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(units=1)))\n",
    "    model.add(tf.keras.layers.Activation(activation='tanh'))\n",
    "    return tf.keras.Model(x, model(x))\n",
    "              \n",
    "generator = build_generator(\n",
    "    input_shape=generator_input_shape,\n",
    "    generator_reshape_dim=generator_reshape_dim,\n",
    "    generator_reshape_shape=generator_reshape_shape,\n",
    ")\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "928b7ad3-2038-4602-a229-2a58ba91fcd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_22 (InputLayer)        [(None, 100, 1)]          0         \n",
      "_________________________________________________________________\n",
      "sequential_24 (Sequential)   (None, 1)                 67393     \n",
      "=================================================================\n",
      "Total params: 67,393\n",
      "Trainable params: 67,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def build_critic_x(input_shape):\n",
    "    x = tf.keras.Input(shape=input_shape)\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.Conv1D(filters=64, kernel_size=5))\n",
    "    model.add(tf.keras.layers.LeakyReLU(alpha=0.2))\n",
    "    model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "    model.add(tf.keras.layers.Conv1D(filters=64, kernel_size=5))\n",
    "    model.add(tf.keras.layers.LeakyReLU(alpha=0.2))\n",
    "    model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "    model.add(tf.keras.layers.Conv1D(filters=64, kernel_size=5))\n",
    "    model.add(tf.keras.layers.LeakyReLU(alpha=0.2))\n",
    "    model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "    model.add(tf.keras.layers.Conv1D(filters=64, kernel_size=5))\n",
    "    model.add(tf.keras.layers.LeakyReLU(alpha=0.2))\n",
    "    model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    model.add(tf.keras.layers.Dense(units=1))\n",
    "    return tf.keras.Model(x, model(x))\n",
    "              \n",
    "critic_x = build_critic_x(\n",
    "    input_shape=critic_x_input_shape\n",
    ")\n",
    "critic_x.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "792f35a5-177c-4a40-94a3-9f72dde48214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_17\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_23 (InputLayer)        [(None, 20, 1)]           0         \n",
      "_________________________________________________________________\n",
      "sequential_25 (Sequential)   (None, 1)                 861       \n",
      "=================================================================\n",
      "Total params: 861\n",
      "Trainable params: 861\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def build_critic_z(input_shape, dense_units=20):\n",
    "    x = tf.keras.Input(shape=input_shape)\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    model.add(tf.keras.layers.Dense(units=dense_units))\n",
    "    model.add(tf.keras.layers.LeakyReLU(alpha=0.2))\n",
    "    model.add(tf.keras.layers.Dropout(rate=0.2))\n",
    "    model.add(tf.keras.layers.Dense(units=dense_units))\n",
    "    model.add(tf.keras.layers.LeakyReLU(alpha=0.2))\n",
    "    model.add(tf.keras.layers.Dropout(rate=0.2))\n",
    "    model.add(tf.keras.layers.Dense(units=1))\n",
    "    return tf.keras.Model(x, model(x))\n",
    "              \n",
    "critic_z = build_critic_z(\n",
    "    input_shape=critic_z_input_shape,\n",
    ")\n",
    "critic_z.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "e7972777-6ebf-49ef-b846-bd434440a38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _wasserstein_loss(y_true, y_pred):\n",
    "    return K.mean(y_true * y_pred)\n",
    "\n",
    "def _gradient_penalty_loss(y_true, y_pred, averaged_samples):\n",
    "    gradients = K.gradients(y_pred, averaged_samples)[0]\n",
    "    gradients_sqr = K.square(gradients)\n",
    "    gradients_sqr_sum = K.sum(gradients_sqr, axis=np.arange(1, len(gradients_sqr.shape)))\n",
    "    gradient_l2_norm = K.sqrt(gradients_sqr_sum)\n",
    "    gradient_penalty = K.square(1 - gradient_l2_norm)\n",
    "    return K.mean(gradient_penalty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "725d1e78-5ccd-43d2-8c02-5ab951394ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "09a411d1-13a5-4c46-a084-a5906d4600c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator.trainable = False\n",
    "encoder.trainable = False\n",
    "\n",
    "x = tf.keras.Input(shape=input_shape)\n",
    "y = tf.keras.Input(shape=target_shape)\n",
    "z = tf.keras.Input(shape=(latent_dim, 1))\n",
    "\n",
    "x_ = generator(z)\n",
    "z_ = encoder(x)\n",
    "fake_x = critic_x(x_) # Fake\n",
    "valid_x = critic_x(y) # Truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "c4749b5b-f050-42ef-b1db-bb92b2737240",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = K.random_uniform((64, 1, 1))\n",
    "interpolated_x = (alpha * [y, x_][0]) + ((1 - alpha) * [y, x_][1])\n",
    "validity_interpolated_x = critic_x(interpolated_x)\n",
    "partial_gp_loss_x = partial(_gradient_penalty_loss, averaged_samples=interpolated_x)\n",
    "partial_gp_loss_x.__name__ = 'gradient_penalty'\n",
    "critic_x_model = tf.keras.Model(inputs=[y, z], outputs=[valid_x, fake_x, validity_interpolated_x])\n",
    "critic_x_model.compile(loss=[_wasserstein_loss, _wasserstein_loss, partial_gp_loss_x], \n",
    "                       optimizer=optimizer, loss_weights=[1, 1, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "ade19ad7-cafa-461d-945a-5c4a7596ad50",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_z = critic_z(z_)\n",
    "valid_z = critic_z(z)\n",
    "alpha = K.random_uniform((64, 1, 1))\n",
    "interpolated_z = (alpha * [z, z_][0]) + ((1 - alpha) * [z, z_][1])\n",
    "validity_interpolated_z = critic_z(interpolated_z)\n",
    "partial_gp_loss_z = partial(_gradient_penalty_loss, averaged_samples=interpolated_z)\n",
    "partial_gp_loss_z.__name__ = 'gradient_penalty'\n",
    "critic_z_model = tf.keras.Model(inputs=[x, z], outputs=[valid_z, fake_z,validity_interpolated_z])\n",
    "critic_z_model.compile(loss=[_wasserstein_loss, _wasserstein_loss,\n",
    "                                  partial_gp_loss_z], optimizer=optimizer,\n",
    "                            loss_weights=[1, 1, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "a005d68d-6cb1-4eaf-aeb2-b284d49c2a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "critic_x.trainable = False\n",
    "critic_z.trainable = False\n",
    "generator.trainable = True\n",
    "encoder.trainable = True\n",
    "\n",
    "z_gen = tf.keras.Input(shape=(latent_dim, 1))\n",
    "x_gen_ = generator(z_gen)\n",
    "x_gen = tf.keras.Input(shape=input_shape)\n",
    "z_gen_ = encoder(x_gen)\n",
    "x_gen_rec = generator(z_gen_)\n",
    "fake_gen_x = critic_x(x_gen_)\n",
    "fake_gen_z = critic_z(z_gen_)\n",
    "\n",
    "encoder_generator_model = tf.keras.Model([x_gen, z_gen], [fake_gen_x, fake_gen_z, x_gen_rec])\n",
    "encoder_generator_model.compile(loss=[_wasserstein_loss, _wasserstein_loss, 'mse'], \n",
    "                                optimizer=optimizer,\n",
    "                                loss_weights=[1, 1, 10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e88aa76-aaa4-4b1e-919a-86f1a35e1d34",
   "metadata": {},
   "source": [
    "### Training\n",
    "\n",
    "https://gist.github.com/erenon/91f526302cd8e9d21b73f24c0f9c4bb8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "e8109a68-3727-400a-b89d-568506dd53c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/70, [Dx loss: [-2.0129554  -5.597753    0.77514684  0.280965  ]] [Dz loss: [ 3.8211598  -0.2732207   2.6121001   0.14822808]] [G loss: [ 0.4014206  -0.91131824 -2.1429665   0.34557056]]\n",
      "Epoch: 2/70, [Dx loss: [-5.066792   -9.203266    3.4531922   0.06832839]] [Dz loss: [ 4.151757   -0.18826985  3.4075956   0.09324302]] [G loss: [-2.2937276  -3.3622925  -0.48067975  0.15492444]]\n",
      "Epoch: 3/70, [Dx loss: [-0.18571615 -7.890046    7.4959264   0.02084036]] [Dz loss: [7.1281824e+00 1.4005139e-03 6.2706766e+00 8.5610501e-02]] [G loss: [-7.0533967  -7.244167   -1.5558213   0.17465913]]\n",
      "Epoch: 4/70, [Dx loss: [-1.6173195   5.9525776  -8.080727    0.05108303]] [Dz loss: [2.3114508e+01 1.7453984e-03 2.2085546e+01 1.0272168e-01]] [G loss: [ -3.401511    10.515015   -15.674396     0.17578687]]\n",
      "Epoch: 5/70, [Dx loss: [ -3.3102913    7.805539   -11.512557     0.03967267]] [Dz loss: [52.43507     0.1650541  51.002308    0.12677048]] [G loss: [-32.916107   10.031751  -44.85469     0.1906832]]\n",
      "Epoch: 6/70, [Dx loss: [-3.1220136   3.734029   -7.240716    0.03846725]] [Dz loss: [ -8.523939     0.4360803  -11.199285     0.22392654]] [G loss: [36.295807    7.260922   26.933762    0.21011204]]\n",
      "Epoch: 7/70, [Dx loss: [-3.385384    0.5930588  -4.3705196   0.03920763]] [Dz loss: [-1.6043436e+02  7.3698032e-01 -1.6241611e+02  1.2447836e-01]] [G loss: [1.9902893e+02 4.1565819e+00 1.9294209e+02 1.9302608e-01]]\n",
      "Epoch: 8/70, [Dx loss: [-3.4464865  -0.20989141 -3.6092012   0.03726064]] [Dz loss: [-200.00204      1.1796726 -215.01408      1.3832326]] [G loss: [2.5209251e+02 3.6648502e+00 2.4671082e+02 1.7168315e-01]]\n",
      "Epoch: 9/70, [Dx loss: [-3.3336978  -0.6661082  -3.0089614   0.03413715]] [Dz loss: [8.213012   1.2040035  2.7923086  0.42166927]] [G loss: [12.174561    2.8417509   7.319017    0.20137899]]\n",
      "Epoch: 10/70, [Dx loss: [-3.3027945   0.56868845 -4.2616625   0.03901791]] [Dz loss: [96.929756    1.3029424  94.61175     0.10150656]] [G loss: [-73.66172      4.3605666  -79.72077      0.16984838]]\n",
      "Epoch: 11/70, [Dx loss: [-3.2005754  -4.2767625   0.7343777   0.03418097]] [Dz loss: [-61.145046     1.6009724  -64.370026     0.16239992]] [G loss: [99.42724    -1.3187937  99.035706    0.17103262]]\n",
      "Epoch: 12/70, [Dx loss: [-3.1984096   1.2497234  -4.7305007   0.02823674]] [Dz loss: [-282.60403      2.3992555 -310.56973      2.5566432]] [G loss: [3.6101981e+02 5.5936151e+00 3.5346140e+02 1.9648159e-01]]\n",
      "Epoch: 13/70, [Dx loss: [-3.3886447  -2.0648656  -1.6148075   0.02910287]] [Dz loss: [-118.03884      3.3125062 -134.15631      1.280497 ]] [G loss: [152.95094      0.9667337  150.04332      0.19408704]]\n",
      "Epoch: 14/70, [Dx loss: [-3.382997   -3.609666   -0.06562356  0.02922926]] [Dz loss: [-155.24672      3.4947956 -164.79475      0.605326 ]] [G loss: [1.9735579e+02 6.6949558e-01 1.9507173e+02 1.6145609e-01]]\n",
      "Epoch: 15/70, [Dx loss: [-3.3911624   1.0038574  -4.7121487   0.03171287]] [Dz loss: [-189.16096      3.6553805 -205.5813       1.2764913]] [G loss: [2.3144128e+02 4.6303873e+00 2.2486389e+02 1.9469897e-01]]\n",
      "Epoch: 16/70, [Dx loss: [-3.2259717  -3.3018532  -0.26455015  0.03404311]] [Dz loss: [-173.53938      3.8056154 -196.83575      1.9490732]] [G loss: [2.1412849e+02 6.6394693e-01 2.1164034e+02 1.8242346e-01]]\n",
      "Epoch: 17/70, [Dx loss: [-3.2709491 -1.2915063 -2.2834938  0.0304051]] [Dz loss: [-116.46074      3.9333308 -127.11667      0.67226  ]] [G loss: [149.10269      1.6940657  145.59189      0.18167472]]\n",
      "Epoch: 18/70, [Dx loss: [-3.4363396  -4.0088754   0.2810136   0.02915219]] [Dz loss: [-387.1029      4.106377 -420.3717      2.91624 ]] [G loss: [ 4.7812109e+02 -5.8598155e-01  4.7663297e+02  2.0740861e-01]]\n",
      "Epoch: 19/70, [Dx loss: [-3.3900683  -0.9623882  -2.7255702   0.02978899]] [Dz loss: [-494.93918      4.7751513 -603.3732      10.365892 ]] [G loss: [6.5906421e+02 3.6432030e+00 6.5357568e+02 1.8452942e-01]]\n",
      "Epoch: 20/70, [Dx loss: [-3.6033003   4.3790402  -8.288058    0.03057187]] [Dz loss: [-281.45395      5.6581087 -389.42383     10.231182 ]] [G loss: [4.3340836e+02 9.0786905e+00 4.2259293e+02 1.7367046e-01]]\n",
      "Epoch: 21/70, [Dx loss: [-3.2245398   1.6363219  -5.176093    0.03152313]] [Dz loss: [-240.22893      6.091989  -336.8467       9.0525875]] [G loss: [3.7239951e+02 4.5523572e+00 3.6607809e+02 1.7690921e-01]]\n",
      "Epoch: 22/70, [Dx loss: [-3.3154516  -0.14555654 -3.4805958   0.03107009]] [Dz loss: [-202.59453      6.314948  -278.523        6.9613557]] [G loss: [3.1003787e+02 3.7899692e+00 3.0445163e+02 1.7963409e-01]]\n",
      "Epoch: 23/70, [Dx loss: [-3.324218   -0.51360023 -3.117048    0.03064301]] [Dz loss: [-431.28934     6.882961 -535.7622      9.758999]] [G loss: [5.8836530e+02 3.0293064e+00 5.8350043e+02 1.8355423e-01]]\n",
      "Epoch: 24/70, [Dx loss: [-3.65581    -2.2667756  -1.7179297   0.03288953]] [Dz loss: [-482.40805      7.5471926 -746.96796     25.70127  ]] [G loss: [8.0291034e+02 1.6272678e+00 7.9940747e+02 1.8755968e-01]]\n",
      "Epoch: 25/70, [Dx loss: [-3.4788072 -1.8358065 -1.9859246  0.0342924]] [Dz loss: [-143.35025     8.182038 -387.798      23.626575]] [G loss: [4.1725229e+02 2.0997317e+00 4.1343625e+02 1.7163245e-01]]\n",
      "Epoch: 26/70, [Dx loss: [-3.402223   -0.41107908 -3.2959116   0.03047682]] [Dz loss: [-174.48073      7.9344554 -242.16042      5.9745226]] [G loss: [2.8709622e+02 4.0199618e+00 2.8132352e+02 1.7527586e-01]]\n",
      "Epoch: 27/70, [Dx loss: [-3.3882556   2.3868384  -6.0953646   0.03202696]] [Dz loss: [-418.82068     8.270438 -512.81036     8.57192 ]] [G loss: [5.7980377e+02 5.8458443e+00 5.7214600e+02 1.8119228e-01]]\n",
      "Epoch: 28/70, [Dx loss: [-3.444721   -2.437585   -1.3185905   0.03114549]] [Dz loss: [-521.4048      8.698574 -753.58405    22.348072]] [G loss: [7.9565283e+02 8.7888783e-01 7.9279315e+02 1.9809239e-01]]\n",
      "Epoch: 29/70, [Dx loss: [-3.2998757  -2.65122    -0.9586203   0.03099646]] [Dz loss: [-235.97772     8.83371  -554.9078     31.009642]] [G loss: [5.9291730e+02 1.2127761e+00 5.8992242e+02 1.7821394e-01]]\n",
      "Epoch: 30/70, [Dx loss: [-3.6135237  -2.1074817  -1.8175292   0.03114871]] [Dz loss: [-118.12674     8.433262 -254.84177    12.82818 ]] [G loss: [2.7839331e+02 1.1696049e+00 2.7546640e+02 1.7572780e-01]]\n",
      "Epoch: 31/70, [Dx loss: [-3.6527915  -4.76065     0.7767536   0.03311052]] [Dz loss: [-280.21448     8.677206 -399.25922    11.03675 ]] [G loss: [4.3382053e+02 1.2692674e-01 4.3195493e+02 1.7386794e-01]]\n",
      "Epoch: 32/70, [Dx loss: [-3.801282   -2.2982292  -1.8265527   0.03234996]] [Dz loss: [-291.61008     8.835255 -473.88678    17.344145]] [G loss: [4.9784756e+02 1.6109186e+00 4.9431870e+02 1.9180121e-01]]\n",
      "Epoch: 33/70, [Dx loss: [-3.5024195   5.7337904  -9.556949    0.03207416]] [Dz loss: [ -91.28488     8.975161 -268.28806    16.802803]] [G loss: [2.8879745e+02 9.1497679e+00 2.7767908e+02 1.9686081e-01]]\n",
      "Epoch: 34/70, [Dx loss: [-3.4148183  -5.351432    1.601792    0.03348211]] [Dz loss: [ -53.895252     8.49051   -128.79762      6.6411853]] [G loss: [131.58528     -1.4696555  131.08746      0.19674568]]\n",
      "Epoch: 35/70, [Dx loss: [-3.4169796  -2.3828986  -1.3415197   0.03074384]] [Dz loss: [ -97.86329      8.386694  -175.6122       6.9362245]] [G loss: [194.96777     1.8819355 191.1046      0.198124 ]]\n",
      "Epoch: 36/70, [Dx loss: [-3.387787   -5.004356    1.2880112   0.03285578]] [Dz loss: [-135.51552     8.478016 -229.02109     8.502756]] [G loss: [ 2.4822136e+02 -1.4383713e+00  2.4787288e+02  1.7868452e-01]]\n",
      "Epoch: 37/70, [Dx loss: [-3.315217   -5.3863363   1.764452    0.03066668]] [Dz loss: [ -81.86822     8.505312 -187.27242     9.68989 ]] [G loss: [ 2.0201717e+02 -1.6299201e+00  2.0177660e+02  1.8705036e-01]]\n",
      "Epoch: 38/70, [Dx loss: [-3.298974   -8.616436    5.007991    0.03094705]] [Dz loss: [ -28.065619    8.523249 -136.75368    10.016482]] [G loss: [138.66724     -4.9563475  141.64377      0.19798048]]\n",
      "Epoch: 39/70, [Dx loss: [-3.4698882  -9.52424     5.7450175   0.03093339]] [Dz loss: [-26.748955    8.102498  -98.38614     6.3534684]] [G loss: [100.01417    -5.4566464 103.63202     0.1838792]]\n",
      "Epoch: 40/70, [Dx loss: [-3.506604   -9.385647    5.5773215   0.03017236]] [Dz loss: [ -6.339229    7.9988723 -87.69458     7.3356485]] [G loss: [84.29421    -5.012813   87.484184    0.18228443]]\n",
      "Epoch: 41/70, [Dx loss: [-3.4364145  -1.2764034  -2.480838    0.03208273]] [Dz loss: [-10.926108    7.7103543 -75.303986    5.6667523]] [G loss: [82.30094    2.37207   77.92034    0.2008527]]\n",
      "Epoch: 42/70, [Dx loss: [-3.6225696  -6.0098085   2.0667667   0.03204723]] [Dz loss: [  8.229712   7.422983 -45.825573   4.66323 ]] [G loss: [47.589844  -2.285549  47.93216    0.1943232]]\n",
      "Epoch: 43/70, [Dx loss: [-3.3793185 -5.2766805  1.5833647  0.0313997]] [Dz loss: [ 31.800394    7.198557  -21.405811    4.6007648]] [G loss: [22.439352   -1.8810416  22.505182    0.18152098]]\n",
      "Epoch: 44/70, [Dx loss: [-3.4902818  -4.668794    0.87514406  0.03033691]] [Dz loss: [ 27.624983    6.891319  -14.6870165   3.5420682]] [G loss: [17.872942    0.0258472  16.1322      0.17148961]]\n",
      "Epoch: 45/70, [Dx loss: [-3.521109    0.43539006 -4.269046    0.03125467]] [Dz loss: [ 13.792164   6.520472 -17.622961   2.489465]] [G loss: [24.948814    4.3243117  18.816542    0.18079607]]\n",
      "Epoch: 46/70, [Dx loss: [-3.3446739  -2.2945943  -1.3593644   0.03092848]] [Dz loss: [  3.6765392   6.466304  -24.866545    2.2076783]] [G loss: [29.476648    1.3396578  26.281507    0.18554859]]\n",
      "Epoch: 47/70, [Dx loss: [-3.4734309  -6.4273357   2.6701396   0.02837638]] [Dz loss: [  5.707188    6.357309  -30.16906     2.9518938]] [G loss: [30.709421   -3.2748878  32.146023    0.18382855]]\n",
      "Epoch: 48/70, [Dx loss: [-3.4797297  -7.006035    3.2292037   0.02971018]] [Dz loss: [ -0.65256953   6.106557   -34.55045      2.7791324 ]] [G loss: [34.977024   -3.0363047  36.254787    0.17585443]]\n",
      "Epoch: 49/70, [Dx loss: [-3.3453155  -8.070679    4.4241314   0.03012337]] [Dz loss: [ -5.474434    5.904241  -38.484985    2.7106314]] [G loss: [37.11993    -5.0392823  40.177364    0.19818516]]\n",
      "Epoch: 50/70, [Dx loss: [ -3.5357413  -10.453847     6.62586      0.02922436]] [Dz loss: [ -3.6764987   5.8544984 -37.292953    2.7761955]] [G loss: [33.98972    -6.819508   39.04034     0.17688912]]\n",
      "Epoch: 51/70, [Dx loss: [ -3.484607   -12.392269     8.61018      0.02974837]] [Dz loss: [  1.4066862   5.7927876 -27.892336    2.3506236]] [G loss: [20.926044   -9.164016   28.253626    0.18364327]]\n",
      "Epoch: 52/70, [Dx loss: [ -3.519684   -12.191458     8.368437     0.03033365]] [Dz loss: [ 10.275095    5.658226  -16.918154    2.1535025]] [G loss: [11.276187   -7.7923627  17.296972    0.17715794]]\n",
      "Epoch: 53/70, [Dx loss: [ -3.785045   -11.463802     7.3911176    0.02876402]] [Dz loss: [  8.4896965   5.4815397 -13.018328    1.6026483]] [G loss: [ 6.886251   -8.373641   13.49041     0.17694823]]\n",
      "Epoch: 54/70, [Dx loss: [ -3.553863   -21.18905     17.33467      0.03005172]] [Dz loss: [  4.9107428   5.3491507 -11.751665    1.1313255]] [G loss: [ -4.3768473  -18.134132    12.007287     0.17499979]]\n",
      "Epoch: 55/70, [Dx loss: [ -3.8192086  -20.22713     16.104332     0.03035948]] [Dz loss: [ 6.220601   5.170901  -9.764906   1.0814606]] [G loss: [ -3.4621189  -15.329495     9.794881     0.20724958]]\n",
      "Epoch: 56/70, [Dx loss: [ -3.5479996  -16.336466    12.489132     0.02993345]] [Dz loss: [ 9.805341   4.9863334 -7.0999527  1.1918961]] [G loss: [ -2.6747506  -11.873466     7.399141     0.17995745]]\n",
      "Epoch: 57/70, [Dx loss: [-3.1047144  -4.724708    1.3035346   0.03164587]] [Dz loss: [10.883666   4.8543015 -4.8857174  1.091508 ]] [G loss: [ 6.494667   -0.49978808  5.110626    0.18838291]]\n",
      "Epoch: 58/70, [Dx loss: [-3.53423    -0.55095524 -3.2910984   0.03078234]] [Dz loss: [11.996801   4.66659   -3.812699   1.1142911]] [G loss: [9.800114   4.020289   4.0844665  0.16953592]]\n",
      "Epoch: 59/70, [Dx loss: [-4.033939  -5.4987383  1.1562809  0.0308518]] [Dz loss: [ 9.5829935  4.6016703 -4.3045154  0.9285838]] [G loss: [ 4.3974614  -2.0885084   4.4672737   0.20186962]]\n",
      "Epoch: 60/70, [Dx loss: [-3.164357    3.504622   -6.978137    0.03091584]] [Dz loss: [ 8.334995   4.377637  -5.0884304  0.904579 ]] [G loss: [14.476064    7.196787    5.3596344   0.19196422]]\n",
      "Epoch: 61/70, [Dx loss: [-3.3804934   1.2998523  -4.986007    0.03056623]] [Dz loss: [ 6.8067203   4.2673674  -6.3495955   0.88889503]] [G loss: [13.223868    4.6338778   6.7535024   0.18364881]]\n",
      "Epoch: 62/70, [Dx loss: [ -3.7247474    7.033468   -11.055814     0.02975983]] [Dz loss: [ 3.731935  4.180064 -8.284699  0.783657]] [G loss: [21.278976   10.756549    8.796562    0.17258658]]\n",
      "Epoch: 63/70, [Dx loss: [-3.1605153   2.9228609  -6.3815484   0.02981735]] [Dz loss: [  1.6373914    4.130014   -10.345878     0.78532535]] [G loss: [18.1776     5.5683904 10.511052   0.2098156]]\n",
      "Epoch: 64/70, [Dx loss: [-3.5775793 -9.557833   5.6782684  0.0301986]] [Dz loss: [  0.9096971    4.175962   -11.122324     0.78560597]] [G loss: [ 6.58425    -7.0849433  11.806228    0.18629663]]\n",
      "Epoch: 65/70, [Dx loss: [ -3.3631651  -15.204554    11.536377     0.03050113]] [Dz loss: [  0.6720192   4.044852  -11.29851     0.7925676]] [G loss: [  3.0535088  -10.71146     11.570605     0.21943648]]\n",
      "Epoch: 66/70, [Dx loss: [ -3.3633165 -15.736376   12.069981    0.0303078]] [Dz loss: [  2.12124     4.070164  -10.125794    0.8176869]] [G loss: [  0.4357489  -11.759879    10.241284     0.19543427]]\n",
      "Epoch: 67/70, [Dx loss: [ -3.779193   -14.154648    10.081081     0.02943753]] [Dz loss: [ 3.553506    4.038325   -8.258668    0.77738506]] [G loss: [ 1.416667   -9.096081    8.475588    0.20371602]]\n",
      "Epoch: 68/70, [Dx loss: [-3.3400261  -7.2381544   3.595872    0.03022559]] [Dz loss: [ 5.558084   3.9165986 -5.400588   0.7042075]] [G loss: [ 4.6934185  -3.0354826   5.6726556   0.20562458]]\n",
      "Epoch: 69/70, [Dx loss: [-3.5526843  -5.0367126   1.1796329   0.03043962]] [Dz loss: [ 6.8947997  3.8119416 -2.7810051  0.5863864]] [G loss: [ 3.8933828  -0.79300857  2.7470703   0.1939321 ]]\n",
      "Epoch: 70/70, [Dx loss: [-3.582879  -0.9415712 -2.9544525  0.0313145]] [Dz loss: [ 6.8771744   3.6705055  -1.3337669   0.45404345]] [G loss: [7.1568527  3.9350138  1.382044   0.18397945]]\n"
     ]
    }
   ],
   "source": [
    "fake = np.ones((batch_size, 1))\n",
    "valid = -np.ones((batch_size, 1))\n",
    "delta = np.ones((batch_size, 1))\n",
    "\n",
    "indices = np.arange(X_train.shape[0])\n",
    "\n",
    "epoch_loss = []\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    np.random.shuffle(indices)\n",
    "    X_ = X_train[indices]\n",
    "    y_ = y_train[indices]\n",
    "\n",
    "    epoch_g_loss = []\n",
    "    epoch_cx_loss = []\n",
    "    epoch_cz_loss = []\n",
    "\n",
    "    minibatches_size = batch_size * iterations_critic\n",
    "    num_minibatches = int(X_.shape[0] // minibatches_size)\n",
    "\n",
    "    for i in range(num_minibatches):\n",
    "        minibatch = X_[i * minibatches_size: (i + 1) * minibatches_size]\n",
    "        y_minibatch = y_[i * minibatches_size: (i + 1) * minibatches_size]\n",
    "\n",
    "        for j in range(iterations_critic):\n",
    "            x = minibatch[j * batch_size: (j + 1) * batch_size]\n",
    "            y = y_minibatch[j * batch_size: (j + 1) * batch_size]\n",
    "            z = np.random.normal(size=(batch_size, latent_dim, 1))\n",
    "            epoch_cx_loss.append(\n",
    "                critic_x_model.train_on_batch([y, z], [valid, fake, delta]))\n",
    "            epoch_cz_loss.append(\n",
    "                critic_z_model.train_on_batch([x, z], [valid, fake, delta]))\n",
    "        \n",
    "        epoch_g_loss.append(\n",
    "            encoder_generator_model.train_on_batch([x, z], [valid, valid, y]))\n",
    "        \n",
    "    cx_loss = np.mean(np.array(epoch_cx_loss), axis=0)\n",
    "    cz_loss = np.mean(np.array(epoch_cz_loss), axis=0)\n",
    "    g_loss = np.mean(np.array(epoch_g_loss), axis=0)\n",
    "    \n",
    "    epoch_loss.append([cx_loss, cz_loss, g_loss])\n",
    "    \n",
    "    print('Epoch: {}/{}, [Dx loss: {}] [Dz loss: {}] [G loss: {}]'.format(\n",
    "        epoch, epochs, cx_loss, cz_loss, g_loss))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "efcaafbf-ac9f-4d6a-9376-4fe6e3b03083",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1572066141.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/var/folders/_5/f7yzqnxs6694l3c_yk9mjpzr0000gn/T/ipykernel_85722/1572066141.py\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    [Dx loss: [ -1.239893   -21.721457    20.22298      0.02585853]]\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "[Dx loss: [ -1.239893   -21.721457    20.22298      0.02585853]] \n",
    "[Dz loss: [12.848619   2.4626553 -1.6048353  1.19908  ]] \n",
    "[G loss: [-17.0163     -19.386038     1.6985518    0.06711876]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ad0554-4bf6-47f8-8983-70eb23e10471",
   "metadata": {},
   "outputs": [],
   "source": [
    "[Dx loss: [-0.23936272  9.642991   -9.992036    0.01096798]] \n",
    "[Dz loss: [ 2.4516199   3.1085587  -3.3864095   0.27294713]] \n",
    "[G loss: [13.0496435   8.32087     3.5459964   0.11827757]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6726b03f-3878-4fa8-9190-cf4af06d6833",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "60954f6e-b693-4839-8b7d-7f968ac83e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_ = encoder.predict(X_test)\n",
    "y_hat = generator.predict(z_)\n",
    "critic = critic_x.predict(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d7969402-8d43-4a6e-b005-4e48091a3320",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2276,), (2177,))"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# computes an array of anomaly scores based on a combination of reconstruction error and critic output\n",
    "params = {\"rec_error_type\": \"dtw\", \"comb\": \"mult\"}\n",
    "\n",
    "primitive = load_primitive(\"orion.primitives.tadgan.score_anomalies\", \n",
    "                           arguments=params)\n",
    "errors, true_index, true, predictions = primitive.produce(y=y_test, y_hat=y_hat, critic=critic, index=index_test)\n",
    "\n",
    "errors.shape, true_index.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "2a8184ff-535c-4ab4-a223-7f9eb83d8ae4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 3)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extracts anomalies from sequences of errors following the approach\n",
    "params = {\n",
    "    \"window_size_portion\": 0.33, \n",
    "    \"window_step_size_portion\": 0.1,\n",
    "    \"fixed_threshold\": True\n",
    "}\n",
    "\n",
    "primitive = load_primitive(\"orion.primitives.timeseries_anomalies.find_anomalies\", \n",
    "                           arguments=params)\n",
    "e = primitive.produce(errors=errors, index=true_index)\n",
    "\n",
    "e.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "5e9ba425-266d-4e5a-8b7f-298b20f3d8db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09674728940783987"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_anomalies = [(int(i[0]), int(i[1])) for i in e]\n",
    "start, end = index_test[0], index_test[-1]\n",
    "contextual_f1_score(anomalies, predicted_anomalies, start=start, end=end, weighted=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "e7866b6b-22d6-4ac3-ac5b-1815bee8f69f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09674728940783987"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.07401696222050887\n",
    "0.09674728940783987"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "cb5e5f7e-b6fe-4062-abe5-0f006e58b1c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1150, 1207)]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "1d0873f4-4ab8-46f9-b736-cb1fc09873d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  source  name signal  start   end\n",
      "0   NASA  SMAP    M-2   1110  2250\n"
     ]
    }
   ],
   "source": [
    "print(anomalies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "781bc04b-c77b-4023-ab20-0bf8787ba8cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
